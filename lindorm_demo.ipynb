{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo说明\n",
    "父表(demo表)有一列是context，将其切分为多个chunking，写入子表（demo_chunking）的text字段，切分方式为 title: chunking。子表预先创建搜索索引，数据\n",
    "导入完成后便可进行近似检索，将检索的结果与用户问题进行prompt提交给大模型（可以选择提交chunking后的文本，还是父表中的context字段），便可以实现私域数据知识问答。\n",
    "# 前提条件\n",
    "1. 使用Lindorm新版售卖，开通宽表、搜索、向量、LTS(宽表数据同步搜索使用)、AI（可以提工单，提供aliuid加白后便可开通）\n",
    "2. 宽表引擎在控制台开通S3兼容地址（AI引擎依赖该功能）\n",
    "3. 实例配置白名单，将要运行本文代码的客户端机器IP配置到实例白名单中\n",
    "# 运行环境\n",
    "1. 运行环境: python >= 3.10\n",
    "2. 安装依赖: pip install -r requirements.txt\n",
    "3. 在 env 文件里填写AI、宽表、搜索、dashscope的api key等相关信息\n",
    "4. 本文使用开源数据集：https://github.com/ymcui/cmrc2018/tree/master/squad-style-data，下载 cmrc2018_train.json 完成后，放入 data目录下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from textsplitter import ChineseTextSplitter\n",
    "from ldconfig import Config\n",
    "from opensearchpy import OpenSearch\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "import mysql.connector\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from dashscope import Generation\n",
    "from http import HTTPStatus\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, clear_output, HTML, JSON\n",
    "# 控制opensearch的日志输出级别，防止日志打爆\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('opensearch').setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self):\n",
    "        self.data_path = Config.LOAD_FILE_PATH\n",
    "        self.chunking_size = 200\n",
    "    \n",
    "    def get_all_data(self):\n",
    "        with open(self.data_path, encoding=\"utf-8\") as file:\n",
    "            data = json.load(file)\n",
    "            return data[\"data\"]\n",
    "            \n",
    "    \"\"\"\n",
    "    数据切分方式：能根据长度以及汉语的逗号等切分\n",
    "    \"\"\"\n",
    "    def data_chinese_splite(self, context):\n",
    "        chinese_splitter = ChineseTextSplitter(sentence_size=self.chunking_size)\n",
    "        chunkings = chinese_splitter.split_text(text=context)\n",
    "        return chunkings\n",
    "\n",
    "    \"\"\"\n",
    "    数据切分方式：能根据长度切分\n",
    "    \"\"\"\n",
    "    def data_character_splite(self, context):\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunking_size, chunk_overlap=0)\n",
    "        chunkings = splitter.split_text(text=context)\n",
    "        return chunkings\n",
    "\n",
    "class Lindorm:\n",
    "    def __init__(self):\n",
    "        # 主表名\n",
    "        self.row_parent_table=\"demo\"\n",
    "        # 子表名\n",
    "        self.row_child_table=\"demo_chunking\" \n",
    "        # embedding 模型名\n",
    "        self.embedding_model_name = \"bge_m3_model\"    \n",
    "        # rerank 模型名\n",
    "        self.reranker_model_name = \"rerank_bge_v2_m3\"         \n",
    "        # 文本字段名\n",
    "        self.text_field = \"text\" \n",
    "        # 向量字段名\n",
    "        self.vector_field = \"vector_field\" \n",
    "        # 搜索创建的pipeline名称\n",
    "        self.pipeline_name = \"demo_chunking_embedding_pipeline\" \n",
    "        # 子表创建的索引名，通过show index from demo_chunking 可查看\n",
    "        self.chunking_index_name = \"sidx\" \n",
    "        # 父表字段\n",
    "        self.demo_field = [\"document_id\", \"title\", \"context\", \"status\", \"metadata\"]\n",
    "        # 子表字段\n",
    "        self.demo_chunking_filed = [\"document_id\", \"chunking_position\", \"title\", self.text_field, \"metadata\", \"chunking_number\"]\n",
    "        self.lindormRow = self.LindormRow(self)\n",
    "        self.lindormAI = self.LindormAI(self)\n",
    "        self.lindormSearch = self.LindormSearch(self)\n",
    "    \n",
    "    def close(self):\n",
    "        self.lindormRow.close()\n",
    "    \n",
    "    \"\"\"\n",
    "    使用 mysql.connector 连接宽表\n",
    "    \"\"\"\n",
    "    class LindormRow:\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            self.connection = None\n",
    "            LD_ROW_COFNIG = {\n",
    "                \"host\": Config.ROW_HOST,\n",
    "                \"port\": int(Config.ROW_PORT),\n",
    "                \"user\": Config.LD_USER,\n",
    "                \"passwd\": Config.LD_PASSWORD,\n",
    "                \"db\": \"default\",\n",
    "                \"connection_timeout\": 15\n",
    "            }\n",
    "            try:\n",
    "                self.connection = mysql.connector.connect(**LD_ROW_COFNIG)\n",
    "            except Exception as e:\n",
    "                print(\"Connection error: \", e)\n",
    "                \n",
    "        def common_create_table(self, sql):\n",
    "            cursor = None\n",
    "            try:\n",
    "                cursor = self.connection.cursor(prepared=True)\n",
    "                cursor.execute(sql)\n",
    "            except Exception as e:\n",
    "                print(\"Create error : \", e)\n",
    "            finally:\n",
    "                if cursor != None:\n",
    "                    cursor.close()\n",
    "        \n",
    "        \"\"\"\n",
    "        创建父表语句，可按需修改\n",
    "        \"\"\"\n",
    "        def create_parent_table(self):\n",
    "            sql = \"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {} (\n",
    "                    document_id  VARCHAR, \n",
    "                    title VARCHAR, \n",
    "                    context VARCHAR,\n",
    "                    status   int, \n",
    "                    metadata JSON, \n",
    "                    PRIMARY KEY (document_id)\n",
    "                )\n",
    "            \"\"\".format(self.parent.row_parent_table)\n",
    "            print(\"Create parent table sql: \", sql)\n",
    "            self.common_create_table(sql)\n",
    "            \n",
    "        \"\"\"\n",
    "        创建子表语句，可按需修改\n",
    "        \"\"\"\n",
    "        def create_child_table(self):\n",
    "            sql = \"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {} (\n",
    "                    document_id VARCHAR,\n",
    "                    chunking_position INT,\n",
    "                    title  VARCHAR,\n",
    "                    {}   VARCHAR,\n",
    "                    {} VARCHAR,\n",
    "                    metadata JSON,\n",
    "                    chunking_number INT,\n",
    "                    PRIMARY KEY (document_id, chunking_position)\n",
    "                )\n",
    "            \"\"\".format(self.parent.row_child_table, \n",
    "                       self.parent.text_field, \n",
    "                       self.parent.vector_field)\n",
    "            print(\"Create child table sql: \", sql)\n",
    "            self.common_create_table(sql)\n",
    "                        \n",
    "        \"\"\"\n",
    "        子表创建搜索索引，本文范例中使用的是hnsw索引，如果数据量较大，建议使用ivfpq索引\n",
    "        https://help.aliyun.com/document_detail/2773371.html\n",
    "        \"\"\"\n",
    "        # Reference: https://help.aliyun.com/document_detail/260841.html\n",
    "        def create_child_table_index(self):\n",
    "            sql = \"\"\"\n",
    "            CREATE INDEX IF NOT EXISTS %s USING SEARCH ON %s (\n",
    "                    document_id(indexed=false,columnStored=false),\n",
    "                    chunking_position(indexed=false,columnStored=false),\n",
    "                    title(type=text,analyzer=ik),\n",
    "                    metadata(indexed=false,columnStored=false),\n",
    "                    %s(type=text,analyzer=ik),\n",
    "                    %s(mapping='{\n",
    "                        \"type\": \"knn_vector\",\n",
    "                        \"dimension\": 1024,\n",
    "                        \"data_type\": \"float\",\n",
    "                        \"method\": {\n",
    "                            \"engine\": \"lvector\",\n",
    "                            \"name\": \"hnsw\", \n",
    "                            \"space_type\": \"cosinesimil\",\n",
    "                            \"parameters\": {\n",
    "                                \"ef_construction\": 500,\n",
    "                                \"m\": 24\n",
    "                                }\n",
    "                            }\n",
    "                    }')) WITH (INDEX_SETTINGS='{\n",
    "                    \"index\": {\n",
    "                        \"knn\" : \"true\",\n",
    "                        \"knn.vector_empty_value_to_keep\" : true,\n",
    "                        \"default_pipeline\": \"%s\"\n",
    "                    }}',\n",
    "                        SOURCE_SETTINGS=\n",
    "                        '{\n",
    "                            \"includes\": [\"document_id\", \"chunking_position\",\"title\", \"text\"]\n",
    "                        }',\n",
    "                        numShards=2\n",
    "                    )\n",
    "            \"\"\".strip() %  (self.parent.chunking_index_name, \n",
    "                            self.parent.row_child_table, \n",
    "                            self.parent.text_field, \n",
    "                            self.parent.vector_field, \n",
    "                            self.parent.pipeline_name)\n",
    "            print(\"Create search index sql: \\n \", sql)\n",
    "            self.common_create_table(sql)\n",
    "            \n",
    "        \"\"\"\n",
    "        写入父表接口，其中初始化写入时，status可以设置为0，代表没有chunking写入子表。\n",
    "        \"\"\"\n",
    "        def write_parent(self, data_json: List):\n",
    "            write_fields = \"{},{},{},{},{}\".format(*self.parent.demo_field)\n",
    "            insert_sql = \"\"\"\n",
    "                UPSERT INTO {}({}) VALUES (?, ?, ?, ?, ?) \n",
    "            \"\"\".format(self.parent.row_parent_table, write_fields)\n",
    "            cursor = None\n",
    "            try:\n",
    "                cursor = self.connection.cursor(prepared=True)\n",
    "                for data in data_json:\n",
    "                    write_data = (data[\"document_id\"], \n",
    "                                  data[\"title\"], \n",
    "                                  data[\"context\"], \n",
    "                                  data[\"status\"], \n",
    "                                  json.dumps(data[\"metadata\"], ensure_ascii=False))\n",
    "                    cursor.execute(insert_sql, write_data)\n",
    "            except Exception as e:\n",
    "                print(\"Write error : \", e)\n",
    "            finally:\n",
    "                if cursor != None:\n",
    "                    cursor.close()\n",
    "        \n",
    "        \"\"\"\n",
    "        宽表游标扫描的方式，参考：https://help.aliyun.com/document_detail/440825.html\n",
    "        在数据量较大时能提升宽表scan的性能\n",
    "        \"\"\"\n",
    "        def scan(self, cursor_str: str, offset: int, limit: int) -> Tuple[List, str, int]:\n",
    "            sql_cursor = \"/*+ _l_cursor_ */\"\n",
    "            if cursor_str != \"\" and cursor_str is not None:\n",
    "                sql_cursor = \"/*+ _l_cursor_('{}') */\".format(cursor_str)\n",
    "            sql_var = \" {}, {}, {}, {}, {}\".format(*self.parent.demo_field)\n",
    "            sql = \"SELECT {} {} from {} limit {}, {}\".format(sql_cursor, \n",
    "                                                             sql_var, \n",
    "                                                             self.parent.row_parent_table, \n",
    "                                                             offset, \n",
    "                                                             limit)\n",
    "            results = []\n",
    "            cursor_return = None\n",
    "            offset_return = offset\n",
    "            cursor = None\n",
    "            try:\n",
    "                cursor = self.connection.cursor(prepared=False)\n",
    "                cursor.execute(sql)\n",
    "                rows = cursor.fetchall()        \n",
    "                for row in rows:\n",
    "                    results.append(dict(zip(self.parent.demo_field, row)))\n",
    "                    cursor_return = row[5]\n",
    "                offset_return = offset + limit\n",
    "                return results, cursor_return, offset_return     \n",
    "            except Exception as e:\n",
    "                print(\"Write error : \", e)\n",
    "            finally:\n",
    "                if cursor != None:\n",
    "                    cursor.close()\n",
    "                    \n",
    "        \"\"\"\n",
    "        写入子表：该语句为批量写入 如\n",
    "        UPSERT INTO dmeo_chunking(替换为字段) values (?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        def write_child(self, data_json: List):\n",
    "            write_fields = \"{},{},{},{},{},{}\".format(*self.parent.demo_chunking_filed)\n",
    "            placeholder = \" (?, ?, ?, ?, ?, ?) \"\n",
    "            placeholdes = \", \".join( placeholder for _ in range(len(data_json)))\n",
    "            sql = \"UPSERT INTO {}({}) VALUES {}\".format(self.parent.row_child_table, write_fields, placeholdes)\n",
    "            params = []\n",
    "            for data in data_json:\n",
    "                params.extend(data[field] for field in self.parent.demo_chunking_filed)\n",
    "            cursor = None\n",
    "            try:\n",
    "                cursor = self.connection.cursor(prepared=True)\n",
    "                cursor.execute(sql, tuple(params))\n",
    "            except Exception as e:\n",
    "                print(\"Write error : \", e)\n",
    "            finally:\n",
    "                if cursor != None:\n",
    "                    cursor.close()\n",
    "        \n",
    "        \"\"\"\n",
    "        修改父表的statu，如从0 修改为1 ，业务逻辑同时需要处理，将父表的context进行切分写入子表\n",
    "        \"\"\"\n",
    "        def update_parent_status_sync_child(self, pk: str, status: int):\n",
    "            sql = \"UPSERT INTO {}({},{}) VALUES (?, ?)\".format(self.parent.row_parent_table, \n",
    "                                                               self.parent.demo_field[0], \n",
    "                                                               self.parent.demo_field[3])\n",
    "            cursor = None\n",
    "            try:\n",
    "                cursor = self.connection.cursor(prepared=True)\n",
    "                cursor.execute(sql, (pk, status))\n",
    "            except Exception as e:\n",
    "                print(\"Write error : \", e)\n",
    "            finally:\n",
    "                if cursor != None:\n",
    "                    cursor.close()\n",
    "                    \n",
    "        \"\"\"\n",
    "        根据父表的pk获取context字段信息，与问题一起进行prompt，提交大模型\n",
    "        \"\"\"\n",
    "        def get_parent_context(self, pk: str):\n",
    "            sql = \"\"\"\n",
    "                SELECT {} from {} where {}=?\n",
    "            \"\"\".format(self.parent.demo_field[2],  self.parent.row_parent_table, self.parent.demo_field[0])\n",
    "            cursor = None\n",
    "            try:\n",
    "                cursor = self.connection.cursor(prepared=True)\n",
    "                cursor.execute(sql, (pk,))\n",
    "                row = cursor.fetchone()\n",
    "                return row[0]\n",
    "            except Exception as e:\n",
    "                print(\"Query context err: \", e)\n",
    "            finally:\n",
    "                if cursor != None:\n",
    "                    cursor.close()        \n",
    "            \n",
    "        def close(self):\n",
    "            if self.connection != None:\n",
    "                self.connection.close()\n",
    "\n",
    "    \"\"\"\n",
    "    使用Rest接口访问AI引擎\n",
    "    \"\"\"    \n",
    "    class LindormAI():\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            self.headers = {\n",
    "                \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "                \"x-ld-ak\": Config.LD_USER,\n",
    "                \"x-ld-sk\": Config.LD_PASSWORD\n",
    "                }\n",
    "            \n",
    "        \"\"\"\n",
    "        查询当前model的列表\n",
    "        \"\"\"\n",
    "        def list_modes(self) -> list:\n",
    "            url = \"http://{}:{}/v1/ai/models/list\".format(Config.AI_HOST, Config.AI_PORT)\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"][\"models\"]\n",
    "        \n",
    "        def common_create_model(self, model_name, model_path, task, algorithm):\n",
    "            url = \"http://{}:{}/v1/ai/models/create\".format(Config.AI_HOST, int(Config.AI_PORT))\n",
    "            data = {\n",
    "                \"model_name\": model_name,\n",
    "                \"model_path\": model_path,\n",
    "                \"task\": task,\n",
    "                \"algorithm\": algorithm,\n",
    "                \"settings\": {\"instance_count\": \"2\"}\n",
    "            }\n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                print(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "        \n",
    "        def check_model_exists(self, model_name) -> list: \n",
    "            models = self.list_modes()\n",
    "            for model in models:\n",
    "                if model['name'] == model_name:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        \"\"\"\n",
    "        创建embedding模型，目前推荐使用bge-m3模型即可\n",
    "        \"\"\"\n",
    "        def create_embedding_model(self):\n",
    "            if self.check_model_exists(self.parent.embedding_model_name):\n",
    "                print(\"Model {} exists, skip create\".format(self.parent.embedding_model_name))\n",
    "                return\n",
    "\n",
    "            self.common_create_model(self.parent.embedding_model_name, \n",
    "                                    \"huggingface://BAAI/bge-m3\",\n",
    "                                    \"FEATURE_EXTRACTION\",\n",
    "                                    \"BGE_M3\")\n",
    "          \n",
    "        \"\"\"\n",
    "        创建reranker模型，目前推荐使用 bge-reranker-v2-m3\n",
    "        \"\"\"\n",
    "        def create_reranker_model(self):\n",
    "            if self.check_model_exists(self.parent.reranker_model_name):\n",
    "                print(\"Model {} exists, skip create\".format(self.parent.reranker_model_name))\n",
    "                return\n",
    "            \n",
    "            self.common_create_model(self.parent.reranker_model_name,\n",
    "                                    \"huggingface://BAAI/bge-reranker-v2-m3\",\n",
    "                                    \"SEMANTIC_SIMILARITY\",\n",
    "                                    \"BGE_RERANKER_V2_M3\")\n",
    "        \n",
    "        \"\"\"\n",
    "        对输入的文本文本进行embedding成向量\n",
    "        \"\"\"\n",
    "        def text_embedding(self, input_text:str):\n",
    "            url = \"http://{}:{}/v1/ai/models/{}/infer\".format(Config.AI_HOST, \n",
    "                                                              Config.AI_PORT, \n",
    "                                                              self.parent.embedding_model_name)\n",
    "            input_text_utf8 = input_text.encode('utf-8').decode('utf-8')\n",
    "            data = {\n",
    "                \"input\": [input_text_utf8]\n",
    "            }\n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"][0]\n",
    "\n",
    "        \"\"\"\n",
    "        根据问题以及目前答案的候选集，对答案进行重新排序\n",
    "        * input_text: 输入的问题\n",
    "        * chunks: 答案列表\n",
    "        \"\"\"\n",
    "        def reranker(self, input_text:str,  chunks: List[str]):\n",
    "            url = \"http://{}:{}/v1/ai/models/{}/infer\".format(Config.AI_HOST,\n",
    "                                                              Config.AI_PORT, \n",
    "                                                              self.parent.reranker_model_name)        \n",
    "            data = {\n",
    "                \"input\": {\"query\": input_text, \"chunks\": chunks}\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"]\n",
    "            \n",
    "    \"\"\"\n",
    "    使用opensearch客户端访问搜索引擎\n",
    "    \"\"\"\n",
    "    class LindormSearch():\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            self.top_k = 5\n",
    "            self.index_name = \"default.{}.{}\".format(self.parent.row_child_table,\n",
    "                                                     self.parent.chunking_index_name)\n",
    "            self.client = None\n",
    "            try:\n",
    "                self.client = OpenSearch(\n",
    "                    hosts=[{\"host\": Config.SEARCH_HOST, \"port\": Config.SEARCH_PORT}],\n",
    "                    http_auth=(Config.LD_USER, Config.LD_PASSWORD),\n",
    "                    http_compress=False,\n",
    "                    use_ssl=False,\n",
    "                )\n",
    "            except Exception as e:   \n",
    "                print(\"Connection search error\", e)\n",
    "            \n",
    "        def check_pipeline_exists(self) -> bool:\n",
    "            try:\n",
    "                response = self.client.ingest.get_pipeline(id=self.parent.pipeline_name)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                return False\n",
    "        \n",
    "        \"\"\"\n",
    "        创建pipeline,搜索内部自动对text字段调用ai引擎进行embedding,写入vector_field 字段\n",
    "        \"\"\"\n",
    "        def create_pipeline(self):\n",
    "            if self.check_pipeline_exists():\n",
    "                print(\"Pipeline {} exists\".format(self.parent.pipeline_name))\n",
    "                # 如果pipeline已经存在，目前策略是跳过，如果是需要调整参数重新创建，则注释掉下方的return\n",
    "                return\n",
    "            inner_ai_host = Config.AI_HOST\n",
    "            if \"-pub\" in inner_ai_host:\n",
    "                inner_ai_host = inner_ai_host.replace(\"-pub\", \"-vpc\")\n",
    "                \n",
    "            pipeline = {\n",
    "                \"description\": \"demo_chunking pipeline\",\n",
    "                \"processors\": [\n",
    "                    {\n",
    "                        \"text-embedding\": {\n",
    "                            \"inputFields\": [self.parent.text_field],   \n",
    "                            \"outputFields\": [self.parent.vector_field],\n",
    "                            \"userName\": Config.LD_USER,\n",
    "                            \"password\": Config.LD_PASSWORD,\n",
    "                            \"url\": \"http://{}:{}\".format(inner_ai_host, int(Config.AI_PORT)),\n",
    "                            \"modeName\": self.parent.embedding_model_name\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }    \n",
    "            try:\n",
    "                response = self.client.ingest.put_pipeline(id=self.parent.pipeline_name, body=pipeline)\n",
    "                print(\"Create pipeline success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create pipeline errr \", e)\n",
    "        \n",
    "        \"\"\"\n",
    "        纯文本检索\n",
    "        \"\"\"\n",
    "        def text_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_position\",  \"text\"],\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        self.parent.text_field: text_query\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            res = self.client.search(index=self.index_name, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "        \"\"\"\n",
    "        纯向量检索\n",
    "        \"\"\"\n",
    "        def vector_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            vector = self.parent.lindormAI.text_embedding(text_query)\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_position\",  \"text\"],\n",
    "                \"query\":{\n",
    "                    \"knn\": {\n",
    "                        self.parent.vector_field: {\n",
    "                            \"vector\": vector,\n",
    "                            \"k\": k\n",
    "                        }                      \n",
    "                    }\n",
    "                },\n",
    "                \"ext\": {\"lvector\":{\"ef_search\": \"200\"}}\n",
    "            }\n",
    "            res = self.client.search(index=self.index_name, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "        \"\"\"\n",
    "        全文、向量融合检索\n",
    "        \"\"\"\n",
    "        def rrf_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            vector = self.parent.lindormAI.text_embedding(text_query)\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_position\",  \"text\"],\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                    self.parent.vector_field: { \n",
    "                        \"vector\": vector,\n",
    "                        \"filter\": {\n",
    "                            \"match\": {\n",
    "                                self.parent.text_field: text_query,\n",
    "                            }\n",
    "                        },\n",
    "                        \"k\": k\n",
    "                      }\n",
    "                    }\n",
    "                },\n",
    "                \"ext\": {\"lvector\": {\n",
    "                    \"hybrid_search_type\": \"filter_rrf\", \n",
    "                    \"rrf_rank_constant\": \"60\",\n",
    "                    \"ef_search\": \"200\"\n",
    "                }}\n",
    "            }\n",
    "            res = self.client.search(index=self.index_name, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "\n",
    "\"\"\"\n",
    "使用api_key访问通义前问的方式\n",
    "\"\"\"\n",
    "# reference: https://help.aliyun.com/zh/dashscope/developer-reference/qwen-api\n",
    "class AliQwen():\n",
    "    def __init__(self):\n",
    "        self.api_key = Config.DASHSCOPE_API_KEY\n",
    "        self.model_name = \"qwen-turbo\"\n",
    "        self.PROMPT_TEMPLATE = \"\"\"已知信息：\n",
    "{context} \n",
    "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：{question}\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    非流式对话大模型\n",
    "    \"\"\"\n",
    "    def chat(self, prompt: str):\n",
    "        response = Generation.call(model=self.model_name, prompt=prompt, stream=False, api_key=self.api_key)\n",
    "        if response.status_code == HTTPStatus.OK:\n",
    "            return response.output.text\n",
    "        else:\n",
    "            raise Exception(response.message)\n",
    "    \n",
    "    \"\"\"\n",
    "    流式对话大模型\n",
    "    \"\"\"\n",
    "    def chat_stream(self, prompt: str):\n",
    "        responses = Generation.call(model=self.model_name, prompt=prompt, stream=True, api_key=self.api_key)\n",
    "        for response in responses:\n",
    "            if response.status_code == HTTPStatus.OK:\n",
    "                yield response.output.text\n",
    "            else:\n",
    "                raise Exception(response.message)\n",
    "    \n",
    "    \"\"\"\n",
    "    问题与相关提示一起组装\n",
    "    \"\"\"\n",
    "    def gen_prompt(self, query: str, context: str):\n",
    "        return self.PROMPT_TEMPLATE.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "\n",
    "\"\"\"\n",
    "处理rerank之后的结果，如为每个json对象添加 rerank_score 字段标识为rerank之后的得分\n",
    "\"\"\"\n",
    "def handler_reranker(origin_result, reranker_result, topk):\n",
    "    reranked_origin_result = []\n",
    "    for score_item in reranker_result:\n",
    "        index = score_item['index']\n",
    "        if index < len(origin_result):\n",
    "            original = origin_result[index]\n",
    "            original['rerank_score'] = score_item['score']\n",
    "            reranked_origin_result.append(original)\n",
    "    return reranked_origin_result[0:topk]\n",
    "\n",
    "\"\"\"\n",
    "打印工具\n",
    "\"\"\"\n",
    "def wrap_text(text, width):\n",
    "    wrapped_lines = []\n",
    "    for line in text.splitlines():\n",
    "            wrapped_lines.extend([line[i:i + width] for i in range(0, len(line), width)])\n",
    "    return \"\\n\".join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意：下方代码请严格按照顺序执行，也可以拆分后按顺序一个一个执行\n",
    "- 宽表引擎: 通过 mysql -h替换宽表实例域名 -P33060 -p替换密码 -uroot 可以链接宽表引擎, show tables;  show index from demo_chunking命令可以查看相关命令执行情况\n",
    "- AI引擎: 可以通过调用list_modes 查看 模型创建的情况, 只有  status状态为 READY 才可以提供服务\n",
    "- 搜索引擎: 可以通过 check_pipeline_exists 查看pipeline的创建情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create parent table sql:  \n",
      "                CREATE TABLE IF NOT EXISTS demo (\n",
      "                    document_id  VARCHAR, \n",
      "                    title VARCHAR, \n",
      "                    context VARCHAR,\n",
      "                    status   int, \n",
      "                    metadata JSON, \n",
      "                    PRIMARY KEY (document_id)\n",
      "                )\n",
      "            \n",
      "Create child table sql:  \n",
      "                CREATE TABLE IF NOT EXISTS demo_chunking (\n",
      "                    document_id VARCHAR,\n",
      "                    chunking_position INT,\n",
      "                    title  VARCHAR,\n",
      "                    text   VARCHAR,\n",
      "                    vector_field VARCHAR,\n",
      "                    metadata JSON,\n",
      "                    chunking_number INT,\n",
      "                    PRIMARY KEY (document_id, chunking_position)\n",
      "                )\n",
      "            \n",
      "Model bge_m3_model exists, skip create\n",
      "Model rerank_bge_v2_m3 exists, skip create\n",
      "models:  [\n",
      "    {\n",
      "        \"name\": \"rerank_bge_v2_m3\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2024-11-08T21:03:49.627+08:00\",\n",
      "        \"update_time\": \"2024-11-08T21:04:22.589+08:00\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"jishu_bge_model\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2024-11-19T20:35:11.705+08:00\",\n",
      "        \"update_time\": \"2024-11-19T20:35:13.833+08:00\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"bge_m3_model\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2024-11-08T21:16:26.562+08:00\",\n",
      "        \"update_time\": \"2024-11-08T21:17:18.845+08:00\"\n",
      "    }\n",
      "]\n",
      "Pipeline demo_chunking_embedding_pipeline exists\n",
      "Create search index sql: \n",
      "  CREATE INDEX IF NOT EXISTS sidx USING SEARCH ON demo_chunking (\n",
      "                    document_id(indexed=false,columnStored=false),\n",
      "                    chunking_position(indexed=false,columnStored=false),\n",
      "                    title(type=text,analyzer=ik),\n",
      "                    metadata(indexed=false,columnStored=false),\n",
      "                    text(type=text,analyzer=ik),\n",
      "                    vector_field(mapping='{\n",
      "                        \"type\": \"knn_vector\",\n",
      "                        \"dimension\": 1024,\n",
      "                        \"data_type\": \"float\",\n",
      "                        \"method\": {\n",
      "                            \"engine\": \"lvector\",\n",
      "                            \"name\": \"hnsw\", \n",
      "                            \"space_type\": \"cosinesimil\",\n",
      "                            \"parameters\": {\n",
      "                                \"ef_construction\": 500,\n",
      "                                \"m\": 24\n",
      "                                }\n",
      "                            }\n",
      "                    }')) WITH (INDEX_SETTINGS='{\n",
      "                    \"index\": {\n",
      "                        \"knn\" : \"true\",\n",
      "                        \"knn.vector_empty_value_to_keep\" : true,\n",
      "                        \"default_pipeline\": \"demo_chunking_embedding_pipeline\"\n",
      "                    }}',\n",
      "                        SOURCE_SETTINGS=\n",
      "                        '{\n",
      "                            \"includes\": [\"document_id\", \"chunking_position\",\"title\", \"text\"]\n",
      "                        }',\n",
      "                        numShards=2\n",
      "                    )\n"
     ]
    }
   ],
   "source": [
    "def main_lindorm():\n",
    "    lindorm = Lindorm()\n",
    "    # 宽表: 创建父表，通过musla\n",
    "    lindorm.lindormRow.create_parent_table()\n",
    "    # 宽表: 创建子表\n",
    "    lindorm.lindormRow.create_child_table()\n",
    "    # AI: 创建AI embedding 模型\n",
    "    lindorm.lindormAI.create_embedding_model()\n",
    "    # AI: 创建AI reranker 模型\n",
    "    lindorm.lindormAI.create_reranker_model()\n",
    "    # AI: 查看AI现有模型\n",
    "    models = lindorm.lindormAI.list_modes()\n",
    "    print(\"models: \", json.dumps(models, indent=4, ensure_ascii=False))\n",
    "    # 搜索: 创建pipeline, 这样在写入text 字段时，搜索引擎内部会自动调用AI引擎进行embedding，生成向量 vector_field 字段\n",
    "    lindorm.lindormSearch.create_pipeline()\n",
    "    # 宽表: 为 demo_chunking 创建 搜索索引\n",
    "    lindorm.lindormRow.create_child_table_index()   \n",
    "    lindorm.close()\n",
    "\n",
    "main_lindorm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方为写入父表（demo表）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total data:  2403  each processing batch:  100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Data: 100%|██████████| 25/25 [03:28<00:00,  8.35s/batch]\n"
     ]
    }
   ],
   "source": [
    "def demo_write_parent_data():\n",
    "    lindorm = Lindorm()\n",
    "    data_handler = DataHandler()\n",
    "    datas = data_handler.get_all_data()\n",
    "    data_count = len(datas)  \n",
    "    batch_size = 100\n",
    "    print(\"total data: \", data_count, \" each processing batch: \", batch_size)\n",
    "    for i in tqdm(range(0, data_count, batch_size), desc=\"Writing Data\", unit=\"batch\"):\n",
    "        batch_data = []\n",
    "        for j in range(i, min(i+batch_size, data_count)):\n",
    "            data = datas[j]\n",
    "            writeJson = {\n",
    "                \"document_id\": data['id'],\n",
    "                \"title\": data['title'],\n",
    "                \"context\": data['paragraphs'][0][\"context\"],\n",
    "                \"status\": 0,\n",
    "                \"metadata\": {\"source\": Config.LOAD_FILE_PATH}\n",
    "            }\n",
    "            batch_data.append(writeJson)\n",
    "        lindorm.lindormRow.write_parent(batch_data)\n",
    "    lindorm.close()\n",
    "# 确保仅执行一次即可, 有写入需求请打开下方注释\n",
    "#demo_write_parent_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "父表中的context进行切分写入子表。需要了解切分后的格式以便于业务选择合适的切分方式\n",
    "- RecursiveCharacterTextSplitter 严格按照长度切分\n",
    "- ChineseTextSplitter 长度以及中的逗号等分割\n",
    "切分效果可以查看下方的输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>原始文档: NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>RecursiveCharacterTextSplitter 切分方式： </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni\n",
      "Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>ChineseTextSplitter 切分方式： </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。\n",
      "NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。\n",
      "用双筒望远镜或小型望远镜就能看到个别的行星。\n",
      "NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。\n",
      "这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。\n"
     ]
    }
   ],
   "source": [
    "# 数据切分选择\n",
    "def demo_data_chunking():\n",
    "    data_handler = DataHandler()\n",
    "    datas = data_handler.get_all_data()\n",
    "    context = datas[3]['paragraphs'][0][\"context\"]\n",
    "    wrapped_text = wrap_text(context, 120)\n",
    "    display(HTML(f\"<pre>原始文档: {context}</pre>\"))\n",
    "    chunkings = data_handler.data_character_splite(context)\n",
    "    display(HTML(f\"<pre style='color: red;'>RecursiveCharacterTextSplitter 切分方式： </pre>\"))\n",
    "    for chunking in chunkings:\n",
    "        print(chunking)\n",
    "    chunkings = data_handler.data_chinese_splite(context)\n",
    "    display(HTML(f\"<pre style='color: red;'>ChineseTextSplitter 切分方式： </pre>\"))\n",
    "    for chunking in chunkings:\n",
    "        print(chunking)\n",
    "demo_data_chunking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方演示对父表中的context字段进行切分写入子表的text字段，字表中的chunking_position可以记录切分位置,chunking_number记录总的切分数\n",
    "- 使用游标scan宽表的方式扫描父表（demo表）\n",
    "- 需要把父表中的status由0修改为1，代表已经切分子表\n",
    "- 样例使用ChineseTextSplitter切分，有需求可以替换为 RecursiveCharacterTextSplitter 切分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Writing Chunking Data: 100%|██████████| 1000/1000 [14:54<00:00,  1.12batch/s]\n",
      "Writing Chunking Data: 100%|██████████| 1000/1000 [14:54<00:00,  1.12batch/s]\n",
      "Writing Chunking Data: 100%|██████████| 403/403 [06:00<00:00,  1.12batch/s]\n"
     ]
    }
   ],
   "source": [
    "def scan_update_parent_status_write_child():\n",
    "    lindorm = Lindorm()\n",
    "    data_handler = DataHandler()\n",
    "    cursor = None\n",
    "    offset = 0\n",
    "    limit = 1000\n",
    "    while True:\n",
    "        results, cursor, offset = lindorm.lindormRow.scan(cursor, offset, limit)\n",
    "        for result in tqdm(results, desc=\"Writing Chunking Data\", unit=\"batch\"):\n",
    "            if int(result[\"status\"]) == 0:\n",
    "                title = result[\"title\"]\n",
    "                lindorm.lindormRow.update_parent_status_sync_child(result[\"document_id\"], 1)\n",
    "                context = result[\"context\"]\n",
    "                chunkings = data_handler.data_chinese_splite(context)\n",
    "                chunking_number = len(chunkings)\n",
    "                document_id = result[\"document_id\"]\n",
    "                batch_data = []\n",
    "                for i in range(chunking_number):\n",
    "                    write_data = {\n",
    "                        \"document_id\": document_id,\n",
    "                        \"chunking_position\": i,\n",
    "                        \"title\": title,\n",
    "                        \"text\": \"{}: {}\".format( title, chunkings[i]),\n",
    "                        \"metadata\": result[\"metadata\"],\n",
    "                        \"chunking_number\": chunking_number\n",
    "                    }\n",
    "                    batch_data.append(write_data)\n",
    "                lindorm.lindormRow.update_parent_status_sync_child(document_id, 1)\n",
    "                lindorm.lindormRow.write_child(batch_data)\n",
    "        if cursor == \"\" or cursor is None:\n",
    "            break\n",
    "        if len(results) == 0:\n",
    "            break    \n",
    "    lindorm.close()\n",
    "# 确保仅执行一次即可，该操作会写入demo_chunking子表，并同步至搜索引擎\n",
    "# scan_update_parent_status_write_child()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方演示：全文、向量混合检索的调用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "_id": "545241494e5f3537330080000000",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:1#vector:2",
        "_score": 0.032522473,
        "_source": {
         "chunking_position": 0,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。"
        }
       },
       {
        "_id": "545241494e5f3537330080000005",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "vector:1",
        "_score": 0.016393442,
        "_source": {
         "chunking_position": 5,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。"
        }
       },
       {
        "_id": "545241494e5f3537330080000003",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:2",
        "_score": 0.016129032,
        "_source": {
         "chunking_position": 3,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 这也是国际科学奥林匹克的其中之一。"
        }
       },
       {
        "_id": "545241494e5f3537330080000007",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "vector:3",
        "_score": 0.015873017,
        "_source": {
         "chunking_position": 7,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。"
        }
       },
       {
        "_id": "545241494e5f3537330080000008",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:3",
        "_score": 0.015873017,
        "_source": {
         "chunking_position": 8,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 每题有4个选择。"
        }
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "rrf_search_result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_rrf_search():\n",
    "    lindorm = Lindorm()\n",
    "    query=\"国际初中科学奥林匹克主要比赛科目\"\n",
    "    results = lindorm.lindormSearch.rrf_search(query)\n",
    "    display(JSON(results, expanded=True, root=\"rrf_search_result\"))\n",
    "    lindorm.close()\n",
    "demo_rrf_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方演示：先全文检索再进行rerank的使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "_id": "545241494e5f3537330080000000",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:1#vector:2",
        "_score": 0.032522473,
        "_source": {
         "chunking_position": 0,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。"
        }
       },
       {
        "_id": "545241494e5f3537330080000005",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:8#vector:1",
        "_score": 0.031099323,
        "_source": {
         "chunking_position": 5,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。"
        }
       },
       {
        "_id": "545241494e5f3537330080000008",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:3#vector:6",
        "_score": 0.031024532,
        "_source": {
         "chunking_position": 8,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 每题有4个选择。"
        }
       },
       {
        "_id": "545241494e5f3537330080000003",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:2#vector:10",
        "_score": 0.030414745,
        "_source": {
         "chunking_position": 3,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 这也是国际科学奥林匹克的其中之一。"
        }
       },
       {
        "_id": "545241494e5f3537330080000004",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:9#vector:4",
        "_score": 0.030117754,
        "_source": {
         "chunking_position": 4,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 考试分成三个独立的部分，在不同的日子进行。"
        }
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "Before rerank result"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": [
       {
        "_id": "545241494e5f353733008000000c",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "vector:5",
        "_score": 0.015384615,
        "_source": {
         "chunking_position": 12,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 故在随机答题的状况，所得分数的期望值为理论系考试以物理、化学与生物学三部分组成。"
        },
        "rerank_score": 0.98682701587677
       },
       {
        "_id": "545241494e5f3537330080000005",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:8#vector:1",
        "_score": 0.031099323,
        "_source": {
         "chunking_position": 5,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。"
        },
        "rerank_score": 0.9855901598930359
       },
       {
        "_id": "545241494e5f3537330080000007",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "vector:3",
        "_score": 0.015873017,
        "_source": {
         "chunking_position": 7,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。"
        },
        "rerank_score": 0.9750074148178101
       },
       {
        "_id": "545241494e5f3537330080000000",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:1#vector:2",
        "_score": 0.032522473,
        "_source": {
         "chunking_position": 0,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。"
        },
        "rerank_score": 0.9329696297645569
       },
       {
        "_id": "545241494e5f3537330080000004",
        "_index": "default.demo_chunking.sidx",
        "_rank_from": "search:9#vector:4",
        "_score": 0.030117754,
        "_source": {
         "chunking_position": 4,
         "document_id": "TRAIN_573",
         "text": "国际初中科学奥林匹克: 考试分成三个独立的部分，在不同的日子进行。"
        },
        "rerank_score": 0.7948654890060425
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "After rerank result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_rerank():\n",
    "    lindorm = Lindorm()\n",
    "    query=\"国际初中科学奥林匹克主要比赛科目\"\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    origin_result = lindorm.lindormSearch.rrf_search(query,  topk * 2)\n",
    "    display(JSON(origin_result[0:topk], expanded=True, root=\"Before rerank result\"))\n",
    "    texts = [item[\"_source\"][\"text\"] for item in origin_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    reranked_origin_result = handler_reranker(origin_result, reranker_result, topk)\n",
    "    display(JSON(reranked_origin_result, expanded=True, root=\"After rerank result\"))\n",
    "    lindorm.close()\n",
    "demo_rerank()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方演示：先进行全文向量混合检索，将混合检索的结果进行rerank，然后将问题以及检索结果一起prompt提交大模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>国际初中科学奥林匹克主要比赛科目是物理、化学和生物学。这些科目分别构成了考试的不同部分。考试包括30道多项选择题，每门科目各占10题。因此，参赛学生需要在这三门\n",
       "科学学科上具备知识才能在比赛中取得好成绩。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>提示模版为:\n",
       "已知信息：\n",
       "国际初中科学奥林匹克: 故在随机答题的状况，所得分数的期望值为理论系考试以物理、化学与生物学三部分组成。\n",
       "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。\n",
       "国际初中科学奥林匹克: 试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。\n",
       "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。\n",
       "国际初中科学奥林匹克: 考试分成三个独立的部分，在不同的日子进行。 \n",
       "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：国际初中科学奥林匹克主要比赛科目</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_chat_with_child_chunking():\n",
    "    lindorm = Lindorm()\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    query=\"国际初中科学奥林匹克主要比赛科目\"\n",
    "    search_result = lindorm.lindormSearch.rrf_search(query, topk * 2)\n",
    "    texts = [item[\"_source\"][\"text\"] for item in search_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    prompt_context = \"\\n\".join(item['chunk'] for item in reranker_result[0:topk])\n",
    "    ali_qwen = AliQwen()\n",
    "    prompt = ali_qwen.gen_prompt(query, prompt_context)\n",
    "    output_text = \"\"\n",
    "    for part in ali_qwen.chat_stream(prompt):\n",
    "        output_text = part \n",
    "        wrapped_text = wrap_text(output_text, 80)\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='color: red;'>{wrapped_text}</pre>\"))\n",
    "    \n",
    "    wrapped_text = wrap_text(prompt, 120)\n",
    "    display(HTML(f\"<pre>提示模版为:\\n{wrapped_text}</pre>\"))\n",
    "    lindorm.close()\n",
    "    \n",
    "demo_chat_with_child_chunking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下方演示：先进行全文向量混合检索，将混合检索的结果进行rerank，然后从父表（demo表）中查询context字段，与问题一起prompt提交大模型回答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>国际初中科学奥林匹克（IJSO）主要的比赛科目包括物理、化学和生物学。这些科目的知识对于参加考试的学生来说是必需的。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>提示模版为:\n",
       "已知信息：\n",
       "国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。此比赛最先在2004年举办，然后一年举办一次。每一个国家／地区可以派出以6名学生\n",
       "及3名领队组成队伍参与赛事。这也是国际科学奥林匹克的其中之一。考试分成三个独立的部分，在不同的日子进行。此考试需要学生拥有科学（即物理、化学与生物学）的知识。以100分为满分。试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。\n",
       "每题有4个选择。每答对一题得1分，每答错一题倒扣0.25分，弃权不扣分。这一部分以30分为满分。依照试验系考试的资料，答中题目的机率为P(C)，而答错题目的机率为P(E)，则formula_1　而　formula_2。故在随机答题的状况，所\n",
       "得分数的期望值为理论系考试以物理、化学与生物学三部分组成。以30分为满分。实验系考试必须以最多三人分成一小组进行，即每一个参赛单位可以分成最多两个小组。在同一小组的所有学生都会有相同的分数。以40分为满分。从第一届至第三届，实验系考试只有一\n",
       "题；而在第四届，实验系考试就分成四题。 \n",
       "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：国际初中科学奥林匹克主要比赛科目</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def demo_chat_with_parent():\n",
    "    lindorm = Lindorm()\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    query=\"国际初中科学奥林匹克主要比赛科目\"\n",
    "    search_result = lindorm.lindormSearch.rrf_search(query, topk * 2)\n",
    "    texts = [item[\"_source\"][\"text\"] for item in search_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    reranked_origin_result = handler_reranker(search_result, reranker_result, topk)\n",
    "    unique_document_ids = list(OrderedDict.fromkeys(item['_source']['document_id'] for item in reranked_origin_result))\n",
    "    contexts = []\n",
    "    for document_id in unique_document_ids:\n",
    "        contexts.append(lindorm.lindormRow.get_parent_context(pk=document_id))\n",
    "    prompt_context = \"\\n\".join(contexts)        \n",
    "    ali_qwen = AliQwen()\n",
    "    prompt = ali_qwen.gen_prompt(query, prompt_context)    \n",
    "    # stream\n",
    "    for part in ali_qwen.chat_stream(prompt):\n",
    "        output_text = part \n",
    "        wrapped_text = wrap_text(output_text, 80)\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='color: red;'>{wrapped_text}</pre>\"))\n",
    "    \n",
    "    wrapped_text = wrap_text(prompt, 120)\n",
    "    display(HTML(f\"<pre>提示模版为:\\n{wrapped_text}</pre>\")) \n",
    "    lindorm.close()\n",
    "\n",
    "demo_chat_with_parent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
