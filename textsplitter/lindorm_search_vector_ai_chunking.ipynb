{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo说明\n",
    "利用Lindorm搜素引擎、向量引擎、AI引擎构建私域知识库场景问答。\n",
    "本demo偏向特殊处理的场景。比如本文中的切分方式是 titile: chunking。\n",
    "父表(demo_parent表)有一列是context，将其切分为多个chunking，写入子表（demo_chunking）的text_field字段，写入方式为 title: chunking。数据\n",
    "导入完成后便可进行近似检索，将检索的结果与用户问题进行prompt提交给大模型（可以选择提交chunking后的文本，还是父表中的context字段），便可以实现私域数据知识问答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy.helpers import bulk\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from textsplitter import ChineseTextSplitter\n",
    "from ldconfig import Config\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm \n",
    "from dashscope import Generation\n",
    "from http import HTTPStatus\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, clear_output, HTML, JSON\n",
    "# 控制opensearch的日志输出级别，防止日志打爆\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('opensearch').setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, chunking_size = 200):\n",
    "        self.data_path = Config.LOAD_FILE_PATH\n",
    "        self.chunking_size = chunking_size\n",
    "            \n",
    "    \"\"\"\n",
    "    数据切分方式：能根据长度以及汉语的逗号等切分\n",
    "    \"\"\"\n",
    "    def data_chinese_splite(self, context):\n",
    "        chinese_splitter = ChineseTextSplitter(sentence_size=self.chunking_size)\n",
    "        chunkings = chinese_splitter.split_text(text=context)\n",
    "        return chunkings\n",
    "\n",
    "    \"\"\"\n",
    "    数据切分方式：能根据长度切分\n",
    "    \"\"\"\n",
    "    def data_character_splite(self, context):\n",
    "        splitter = RecursiveCharacterTextSplitter(chunk_size=self.chunking_size, chunk_overlap=0)\n",
    "        chunkings = splitter.split_text(text=context)\n",
    "        return chunkings\n",
    "    \n",
    "class Lindorm:\n",
    "    def __init__(self):\n",
    "        # embedding 模型名\n",
    "        self.embedding_model_name = \"bge_m3_model\"    \n",
    "        # rerank 模型名\n",
    "        self.reranker_model_name = \"rerank_bge_v2_m3\"\n",
    "        \n",
    "        self.lindormAI = self.LindormAI(self)\n",
    "        self.lindormSearch = self.LindormSearch(self)\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "    使用Rest接口访问AI引擎\n",
    "    \"\"\"    \n",
    "    class LindormAI():\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            self.headers = {\n",
    "                \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "                \"x-ld-ak\": Config.LD_USER,\n",
    "                \"x-ld-sk\": Config.LD_PASSWORD\n",
    "                }\n",
    "            \n",
    "        \"\"\"\n",
    "        查询当前model的列表\n",
    "        \"\"\"\n",
    "        def list_modes(self) -> list:\n",
    "            url = \"http://{}:{}/v1/ai/models/list\".format(Config.AI_HOST, Config.AI_PORT)\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"][\"models\"]\n",
    "        \n",
    "        def common_create_model(self, model_name, model_path, task, algorithm):\n",
    "            url = \"http://{}:{}/v1/ai/models/create\".format(Config.AI_HOST, int(Config.AI_PORT))\n",
    "            data = {\n",
    "                \"model_name\": model_name,\n",
    "                \"model_path\": model_path,\n",
    "                \"task\": task,\n",
    "                \"algorithm\": algorithm,\n",
    "                \"settings\": {\"instance_count\": \"2\"}\n",
    "            }\n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                print(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "        \n",
    "        def check_model_exists(self, model_name) -> list: \n",
    "            models = self.list_modes()\n",
    "            for model in models:\n",
    "                if model['name'] == model_name:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        \"\"\"\n",
    "        创建embedding模型，目前推荐使用bge-m3模型即可\n",
    "        \"\"\"\n",
    "        def create_embedding_model(self):\n",
    "            if self.check_model_exists(self.parent.embedding_model_name):\n",
    "                print(\"Model {} exists, skip create\".format(self.parent.embedding_model_name))\n",
    "                return\n",
    "\n",
    "            self.common_create_model(self.parent.embedding_model_name, \n",
    "                                    \"huggingface://BAAI/bge-m3\",\n",
    "                                    \"FEATURE_EXTRACTION\",\n",
    "                                    \"BGE_M3\")\n",
    "          \n",
    "        \"\"\"\n",
    "        创建reranker模型，目前推荐使用 bge-reranker-v2-m3\n",
    "        \"\"\"\n",
    "        def create_reranker_model(self):\n",
    "            if self.check_model_exists(self.parent.reranker_model_name):\n",
    "                print(\"Model {} exists, skip create\".format(self.parent.reranker_model_name))\n",
    "                return\n",
    "            \n",
    "            self.common_create_model(self.parent.reranker_model_name,\n",
    "                                    \"huggingface://BAAI/bge-reranker-v2-m3\",\n",
    "                                    \"SEMANTIC_SIMILARITY\",\n",
    "                                    \"BGE_RERANKER_V2_M3\")\n",
    "        \n",
    "        \"\"\"\n",
    "        对输入的文本文本进行embedding成向量\n",
    "        \"\"\"\n",
    "        def text_embedding(self, input_text:str):\n",
    "            url = \"http://{}:{}/v1/ai/models/{}/infer\".format(Config.AI_HOST, \n",
    "                                                              Config.AI_PORT, \n",
    "                                                              self.parent.embedding_model_name)\n",
    "            input_text_utf8 = input_text.encode('utf-8').decode('utf-8')\n",
    "            data = {\n",
    "                \"input\": [input_text_utf8]\n",
    "            }\n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"][0]\n",
    "\n",
    "        \"\"\"\n",
    "        根据问题以及目前答案的候选集，对答案进行重新排序\n",
    "        * input_text: 输入的问题\n",
    "        * chunks: 答案列表\n",
    "        \"\"\"\n",
    "        def reranker(self, input_text:str,  chunks: List[str]):\n",
    "            url = \"http://{}:{}/v1/ai/models/{}/infer\".format(Config.AI_HOST,\n",
    "                                                              Config.AI_PORT, \n",
    "                                                              self.parent.reranker_model_name)        \n",
    "            data = {\n",
    "                \"input\": {\"query\": input_text, \"chunks\": chunks}\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"]\n",
    "        \n",
    "        \"\"\"\n",
    "        处理rerank之后的结果，如为每个json对象添加 rerank_score 字段标识为rerank之后的得分\n",
    "        \"\"\"\n",
    "        def handler_reranker(self, origin_result, reranker_result, topk):\n",
    "            reranked_origin_result = []\n",
    "            for score_item in reranker_result:\n",
    "                index = score_item['index']\n",
    "                if index < len(origin_result):\n",
    "                    original = origin_result[index]\n",
    "                    original['rerank_score'] = score_item['score']\n",
    "                    reranked_origin_result.append(original)\n",
    "            return reranked_origin_result[0:topk]\n",
    "            \n",
    "    \"\"\"\n",
    "    使用opensearch客户端访问搜索引擎\n",
    "    \"\"\"\n",
    "    class LindormSearch():\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            # 主表名\n",
    "            self.parent_index= \"demo_parent\"\n",
    "            # 子表名\n",
    "            self.chunking_index=\"demo_chunking\"\n",
    "            \n",
    "            # 文本字段名\n",
    "            self.text_field = \"text_field\" \n",
    "            # 向量字段名\n",
    "            self.vector_field = \"vector_field\" \n",
    "            # 写入pipeline\n",
    "            self.write_pipeline = \"demo_write_embedding_pipeline\" \n",
    "            # 查询pipeline\n",
    "            self.search_pipeline = \"demo_search_embedding_pipeline\"\n",
    "            self.top_k = 5\n",
    "            self.client = None\n",
    "            try:\n",
    "                self.client = OpenSearch(\n",
    "                    hosts=[{\"host\": Config.SEARCH_HOST, \"port\": Config.SEARCH_PORT}],\n",
    "                    http_auth=(Config.LD_USER, Config.LD_PASSWORD),\n",
    "                    http_compress=False,\n",
    "                    use_ssl=False,\n",
    "                    timeout=60\n",
    "                )\n",
    "            except Exception as e:   \n",
    "                print(\"Connection search error\", e)\n",
    "                \n",
    "        \"\"\"\n",
    "        检查写入pipeline是否存在\n",
    "        \"\"\"\n",
    "        def check_write_pipeline_exists(self) -> bool:\n",
    "            try:\n",
    "                response = self.client.ingest.get_pipeline(id=self.write_pipeline)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                return False\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        检查搜索pipeline是否存在\n",
    "        \"\"\"\n",
    "        def check_knn_pipeline_exists(self) -> bool:\n",
    "            try:\n",
    "                response = self.client.search_pipeline.get(id=self.search_pipeline)\n",
    "                print(response)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                return False\n",
    "        \n",
    "        \"\"\"\n",
    "        创建pipleline,搜索内部自动对text字段调用ai引擎进行embedding,写入vector_field 字段\n",
    "        \"\"\"\n",
    "        def create_write_pipeline(self):\n",
    "            print(self.parent.embedding_model_name)\n",
    "            if self.check_write_pipeline_exists():\n",
    "                print(\"Pipeline {} exists\".format(self.write_pipeline))\n",
    "                # 如果pipeline已经存在，目前策略是跳过，如果是需要调整参数重新创建，则注释掉下方的return\n",
    "                return\n",
    "            \n",
    "            inner_ai_host = Config.AI_HOST\n",
    "            if \"-pub\" in inner_ai_host:\n",
    "                inner_ai_host = inner_ai_host.replace(\"-pub\", \"-vpc\")\n",
    "                \n",
    "            pipeline = {\n",
    "                \"description\": \"demo_chunking pipeline\",\n",
    "                \"processors\": [\n",
    "                    {\n",
    "                        \"text-embedding\": {\n",
    "                            \"inputFields\": [self.text_field],   \n",
    "                            \"outputFields\": [self.vector_field],\n",
    "                            \"userName\": Config.LD_USER,\n",
    "                            \"password\": Config.LD_PASSWORD,\n",
    "                            \"url\": \"http://{}:{}\".format(inner_ai_host, int(Config.AI_PORT)),\n",
    "                            \"modeName\": self.parent.embedding_model_name\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }    \n",
    "            try:\n",
    "                response = self.client.ingest.put_pipeline(id=self.write_pipeline, body=pipeline)\n",
    "                print(\"Create pipeline success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create pipeline errr \", e)   \n",
    "        \n",
    "        \"\"\"\n",
    "        创建knn时自动pipleline\n",
    "        \"\"\"\n",
    "        def create_knnsearch_pipeline(self):\n",
    "            if self.check_knn_pipeline_exists():\n",
    "                print(\"Pipeline {} exists\".format(self.search_pipeline))\n",
    "                # 如果pipeline已经存在，目前策略是跳过，如果是需要调整参数重新创建，则注释掉下方的return\n",
    "                return\n",
    "            inner_ai_host = Config.AI_HOST\n",
    "            if \"-pub\" in inner_ai_host:\n",
    "                inner_ai_host = inner_ai_host.replace(\"-pub\", \"-vpc\")\n",
    "\n",
    "            pipeline = {\n",
    "                \"request_processors\": [\n",
    "                    {\n",
    "                        \"text-embedding\": {\n",
    "                            \"tag\": \"auto-query-embedding\",\n",
    "                            \"description\": \"Auto query embedding\",\n",
    "                            \"model_config\": {\n",
    "                                \"inputFields\": [self.text_field],\n",
    "                                \"outputFields\": [self.vector_field],\n",
    "                                \"userName\": Config.LD_USER,\n",
    "                                \"password\": Config.LD_PASSWORD,\n",
    "                                \"url\": \"http://{}:{}\".format(inner_ai_host, int(Config.AI_PORT)),\n",
    "                                \"modeName\": self.parent.embedding_model_name\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            try:\n",
    "                response = self.client.search_pipeline.put(id=self.search_pipeline, body=pipeline)\n",
    "                print(\"Create pipeline success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create pipeline errr \", e)\n",
    "                \n",
    "        def create_parent_index(self):\n",
    "            if self.client.indices.exists(index=self.parent_index):\n",
    "                print(\"Index {} exists\".format(self.parent_index))\n",
    "                return\n",
    "            \n",
    "            index_body = {\n",
    "                \"settings\": {\n",
    "                    \"index\": {\n",
    "                        \"number_of_shards\": 4,\n",
    "                    }\n",
    "                },\n",
    "                \"mappings\": {\n",
    "                    \"properties\": {\n",
    "                        \"document_id\": {\n",
    "                            \"type\": \"keyword\"\n",
    "                        },\n",
    "                        \"title\": {\n",
    "                            \"type\": \"keyword\", \n",
    "                        },\n",
    "                        \"context\": {\n",
    "                            \"type\": \"text\", \n",
    "                            \"analyzer\": \"ik_max_word\", \n",
    "                            \"index\":False,\n",
    "                            \"doc_values\":False\n",
    "                        },\n",
    "                        \"metadata\": {\n",
    "                            \"type\": \"object\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = self.client.indices.create(index=self.parent_index, body=index_body)\n",
    "                print(\"Create parent index success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create index errr \", e)\n",
    "        \n",
    "        def create_chunking_index(self):\n",
    "            if self.client.indices.exists(index=self.chunking_index):\n",
    "                print(\"Index {} exists\".format(self.chunking_index))\n",
    "                return\n",
    "            \n",
    "            # 本文演示的 bge-m3 模型编码后的维度为1024维，因此向量dimension设置为1024\n",
    "            index_body = {\n",
    "                \"settings\": {\n",
    "                    \"index\": {\n",
    "                        \"number_of_shards\": 4,\n",
    "                        \"knn\": True,\n",
    "                        \"default_pipeline\": self.write_pipeline,\n",
    "                        \"search.default_pipeline\": self.search_pipeline\n",
    "                    }\n",
    "                },\n",
    "                \"mappings\": {\n",
    "                    \"_source\": {\n",
    "                        \"excludes\": [self.vector_field]\n",
    "                    },\n",
    "                    \"properties\": {\n",
    "                        \"document_id\": {\n",
    "                            \"type\": \"keyword\"\n",
    "                        },\n",
    "                        self.text_field: {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"ik_max_word\", \n",
    "                        },\n",
    "                        self.vector_field: {\n",
    "                            \"type\": \"knn_vector\",\n",
    "                            \"dimension\": 1024,\n",
    "                            \"data_type\": \"float\",\n",
    "                            \"method\": {\n",
    "                                \"engine\": \"lvector\",\n",
    "                                \"name\": \"hnsw\",\n",
    "                                \"space_type\": \"l2\",\n",
    "                                \"parameters\": {\n",
    "                                    \"m\": 24,\n",
    "                                    \"ef_construction\": 500\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"chunking_number\": {\n",
    "                            \"type\": \"integer\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            try:\n",
    "                response = self.client.indices.create(index=self.chunking_index, body=index_body)\n",
    "                print(\"Create chunking index success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create index errr \", e)\n",
    "        \n",
    "        def write_parent(self, data):\n",
    "            self.client.index(index=self.parent_index, id = data['document_id'], body=data)\n",
    "            \n",
    "        def write_chunking(self, datas):\n",
    "            # 写入 text_field 字段时，会自动embedding为向量写入 vector_field 字段\n",
    "            def gen():\n",
    "                for data in datas:\n",
    "                    yield {\n",
    "                        \"_op_type\": \"index\",\n",
    "                        \"_index\": self.chunking_index,\n",
    "                        \"_id\": data['document_id'] + \"_\" + str(data['chunking_position']),\n",
    "                        \"document_id\": data['document_id'],\n",
    "                        \"text_field\": data['text_field'],\n",
    "                        \"chunking_number\": data['chunking_position'],\n",
    "                    }\n",
    "            (_, errors) = bulk(\n",
    "            self.client, gen(), chunk_size=500, max_retries=2, request_timeout=120)\n",
    "        \n",
    "        def get_parent_context(self, document_id):\n",
    "            res = self.client.get(index=self.parent_index, id=document_id)\n",
    "            return res['_source']['context']\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        纯文本检索\n",
    "        \"\"\"\n",
    "        def text_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_number\",  self.text_field],\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        self.text_field: text_query\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            res = self.client.search(index=self.chunking_index, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "        \"\"\"\n",
    "        纯向量检索，用例中使用查询自动embedding功能\n",
    "        \"\"\"\n",
    "        def vector_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_number\",  self.text_field],\n",
    "                \"query\":{\n",
    "                    \"knn\": {\n",
    "                        self.vector_field: {\n",
    "                            \"query_text\": text_query,\n",
    "                            \"k\": k\n",
    "                        }                      \n",
    "                    }\n",
    "                },\n",
    "                \"ext\": {\"lvector\":{\"ef_search\": \"200\"}}\n",
    "            }\n",
    "            res = self.client.search(index=self.chunking_index, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "        \"\"\"\n",
    "        全文、向量融合检索，用例中使用查询自动embedding功能\n",
    "        \"\"\"\n",
    "        def rrf_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_number\", \"text_field\"],\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                    self.vector_field: { \n",
    "                        \"query_text\": text_query,\n",
    "                        \"filter\": {\n",
    "                            \"match\": {\n",
    "                                self.text_field: text_query,\n",
    "                            }\n",
    "                        },\n",
    "                        \"k\": k\n",
    "                      }\n",
    "                    }\n",
    "                },\n",
    "                \"ext\": {\"lvector\": {\n",
    "                    \"hybrid_search_type\": \"filter_rrf\", \n",
    "                    \"rrf_rank_constant\": \"1\",\n",
    "                    \"ef_search\": \"200\"\n",
    "                }}\n",
    "            }\n",
    "            res = self.client.search(index=self.chunking_index, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "使用api_key访问通义前问的方式\n",
    "\"\"\"\n",
    "# reference: https://help.aliyun.com/zh/dashscope/developer-reference/qwen-api\n",
    "class AliQwen():\n",
    "    def __init__(self):\n",
    "        self.api_key = Config.DASHSCOPE_API_KEY\n",
    "        self.model_name = \"qwen-plus\"\n",
    "        self.PROMPT_TEMPLATE = \"\"\"已知信息：\n",
    "{context} \n",
    "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：{question}\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    非流式对话大模型\n",
    "    \"\"\"\n",
    "    def chat(self, prompt: str):\n",
    "        response = Generation.call(model=self.model_name, prompt=prompt, stream=False, api_key=self.api_key)\n",
    "        if response.status_code == HTTPStatus.OK:\n",
    "            return response.output.text\n",
    "        else:\n",
    "            raise Exception(response.message)\n",
    "    \n",
    "    \"\"\"\n",
    "    流式对话大模型\n",
    "    \"\"\"\n",
    "    def chat_stream(self, prompt: str):\n",
    "        responses = Generation.call(model=self.model_name, prompt=prompt, stream=True, api_key=self.api_key)\n",
    "        for response in responses:\n",
    "            if response.status_code == HTTPStatus.OK:\n",
    "                yield response.output.text\n",
    "            else:\n",
    "                raise Exception(response.message)\n",
    "    \n",
    "    \"\"\"\n",
    "    问题与相关提示一起组装\n",
    "    \"\"\"\n",
    "    def gen_prompt(self, query: str, context: str):\n",
    "        return self.PROMPT_TEMPLATE.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "\n",
    "\"\"\"\n",
    "打印工具\n",
    "\"\"\"\n",
    "def wrap_text(text, width):\n",
    "    wrapped_lines = []\n",
    "    for line in text.splitlines():\n",
    "            wrapped_lines.extend([line[i:i + width] for i in range(0, len(line), width)])\n",
    "    return \"\\n\".join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bge_m3_model exists, skip create\n",
      "Model rerank_bge_v2_m3 exists, skip create\n"
     ]
    }
   ],
   "source": [
    "def ai_model():\n",
    "    lindorm = Lindorm()\n",
    "    # AI: 创建AI embedding 模型\n",
    "    lindorm.lindormAI.create_embedding_model()\n",
    "    # AI: 创建AI reranker 模型\n",
    "    lindorm.lindormAI.create_reranker_model()\n",
    "ai_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models:  [\n",
      "    {\n",
      "        \"name\": \"rerank_bge_v2_m3\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2025-03-10T20:01:26.002+08:00\",\n",
      "        \"update_time\": \"2025-03-10T20:03:28.997+08:00\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"bge_m3_model\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2025-03-10T20:01:25.598+08:00\",\n",
      "        \"update_time\": \"2025-03-10T20:02:58.952+08:00\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "lindorm = Lindorm()\n",
    "def ai_check_model_ready():\n",
    "    models = lindorm.lindormAI.list_modes()\n",
    "    # 等待部署的status为READY后，进行下一步\n",
    "    print(\"models: \", json.dumps(models, indent=4, ensure_ascii=False))\n",
    "ai_check_model_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bge_m3_model\n",
      "Pipeline demo_write_embedding_pipeline exists\n",
      "{'demo_search_embedding_pipeline': {'request_processors': [{'text-embedding': {'tag': 'auto-query-embedding', 'description': 'Auto query embedding', 'model_config': {'inputFields': ['text_field'], 'outputFields': ['vector_field'], 'userName': 'root', 'password': 'eUxmlnqBlUze', 'url': 'http://ld-2zeq6izld90k65s3e-proxy-ai-vpc.lindorm.aliyuncs.com:9002', 'modeName': 'bge_m3_model'}}}]}}\n",
      "Pipeline demo_search_embedding_pipeline exists\n",
      "Create parent index success {'acknowledged': True, 'shards_acknowledged': True, 'index': 'demo_parent'}\n",
      "Create chunking index success {'acknowledged': True, 'shards_acknowledged': True, 'index': 'demo_chunking'}\n"
     ]
    }
   ],
   "source": [
    "lindorm = Lindorm()\n",
    "def search_init():\n",
    "    # Search: 创建写入pipeline\n",
    "    lindorm.lindormSearch.create_write_pipeline()\n",
    "    # # Search: 创建搜索pipeline\n",
    "    lindorm.lindormSearch.create_knnsearch_pipeline()\n",
    "    # # Search: 创建主表\n",
    "    lindorm.lindormSearch.create_parent_index()\n",
    "    # # Search: 创建子表\n",
    "    lindorm.lindormSearch.create_chunking_index()\n",
    "    \n",
    "search_init()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre>原始文档: NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>RecursiveCharacterTextSplitter 切分方式： </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。用双筒望远镜或小型望远镜就能看到个别的行星。NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni\n",
      "Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>ChineseTextSplitter 切分方式： </pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NGC 6231是一个位于天蝎座的疏散星团，天球座标为赤经16时54分，赤纬-41度48分，视觉观测大小约45角分，亮度约2.6视星等，距地球5900光年。\n",
      "NGC 6231年龄约为三百二十万年，是一个非常年轻的星团，星团内的最亮星是5等的天蝎座 ζ1星。\n",
      "用双筒望远镜或小型望远镜就能看到个别的行星。\n",
      "NGC 6231在1654年被意大利天文学家乔瓦尼·巴蒂斯特·霍迪尔纳（Giovanni Battista Hodierna）以Luminosae的名字首次纪录在星表中，但是未见记载于夏尔·梅西耶的天体列表和威廉·赫歇尔的深空天体目录。\n",
      "这个天体在1678年被爱德蒙·哈雷（I.7）、1745年被夏西亚科斯（Jean-Phillippe Loys de Cheseaux）（9）、1751年被尼可拉·路易·拉卡伊（II.13）分别再次独立发现。\n"
     ]
    }
   ],
   "source": [
    "# 数据切分选择\n",
    "def demo_data_chunking():\n",
    "    path = \"./data/processed_cmrc2018_train.json\"\n",
    "    with open(path, encoding=\"utf-8\") as file:\n",
    "        datas = json.load(file)\n",
    "    context = datas[3][\"context\"]\n",
    "    wrapped_text = wrap_text(context, 120)\n",
    "    display(HTML(f\"<pre>原始文档: {context}</pre>\"))\n",
    "    data_handler = DataHandler(200)\n",
    "    chunkings = data_handler.data_character_splite(context)\n",
    "    display(HTML(f\"<pre style='color: red;'>RecursiveCharacterTextSplitter 切分方式： </pre>\"))\n",
    "    for chunking in chunkings:\n",
    "        print(chunking)\n",
    "    chunkings = data_handler.data_chinese_splite(context)\n",
    "    display(HTML(f\"<pre style='color: red;'>ChineseTextSplitter 切分方式： </pre>\"))\n",
    "    for chunking in chunkings:\n",
    "        print(chunking)\n",
    "demo_data_chunking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Docs: 100%|█| 2403/2403 \n"
     ]
    }
   ],
   "source": [
    "def data_loader():\n",
    "    lindorm = Lindorm()\n",
    "    data_handler = DataHandler(200)\n",
    "    path = \"./data/processed_cmrc2018_train.json\"\n",
    "    with open(path, encoding=\"utf-8\") as file:\n",
    "        docs = json.load(file)\n",
    "    for index, doc in tqdm(enumerate(docs), total=len(docs), desc=\"Processing Docs\"):\n",
    "        metadata = {\n",
    "            \"source\": path\n",
    "        }\n",
    "        write_data = {\n",
    "            \"document_id\": doc['id'],\n",
    "            \"title\": doc['title'],\n",
    "            \"context\": doc['context'],\n",
    "            \"metadata\": metadata\n",
    "        }\n",
    "        lindorm.lindormSearch.write_parent(write_data)\n",
    "        chunkings = data_handler.data_chinese_splite(doc['context'])\n",
    "        write_chunkings = []\n",
    "        for index, chunking in enumerate(chunkings):\n",
    "            chunking_data = {\n",
    "                    \"document_id\": doc['id'],\n",
    "                    \"text_field\": \"{}: {}\".format(doc['title'], chunking),\n",
    "                    \"chunking_position\": index\n",
    "                }\n",
    "            write_chunkings.append(chunking_data)\n",
    "        lindorm.lindormSearch.write_chunking(write_chunkings)\n",
    "            \n",
    "data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "_id": "TRAIN_573_0",
        "_index": "demo_chunking",
        "_score": 0.8333334,
        "_source": {
         "chunking_number": 0,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。"
        }
       },
       {
        "_id": "TRAIN_573_5",
        "_index": "demo_chunking",
        "_score": 0.5,
        "_source": {
         "chunking_number": 5,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。"
        }
       },
       {
        "_id": "TRAIN_573_3",
        "_index": "demo_chunking",
        "_score": 0.33333334,
        "_source": {
         "chunking_number": 3,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 这也是国际科学奥林匹克的其中之一。"
        }
       },
       {
        "_id": "TRAIN_573_13",
        "_index": "demo_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 13,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 以30分为满分。"
        }
       },
       {
        "_id": "TRAIN_573_7",
        "_index": "demo_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 7,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。"
        }
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "rrf_search_result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 下方演示：全文、向量混合 检索的调用方式\n",
    "def demo_rrf_search(query):\n",
    "    lindorm = Lindorm()\n",
    "    results = lindorm.lindormSearch.rrf_search(query)\n",
    "    display(JSON(results, expanded=True, root=\"rrf_search_result\"))\n",
    "    lindorm.close()\n",
    "query=\"国际初中科学奥林匹克主要比赛科目\"    \n",
    "demo_rrf_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "_id": "TRAIN_573_0",
        "_index": "demo_chunking",
        "_score": 0.8333334,
        "_source": {
         "chunking_number": 0,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。"
        }
       },
       {
        "_id": "TRAIN_573_5",
        "_index": "demo_chunking",
        "_score": 0.6111111,
        "_source": {
         "chunking_number": 5,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。"
        }
       },
       {
        "_id": "TRAIN_573_3",
        "_index": "demo_chunking",
        "_score": 0.42424244,
        "_source": {
         "chunking_number": 3,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 这也是国际科学奥林匹克的其中之一。"
        }
       },
       {
        "_id": "TRAIN_573_8",
        "_index": "demo_chunking",
        "_score": 0.30952382,
        "_source": {
         "chunking_number": 8,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 每题有4个选择。"
        }
       },
       {
        "_id": "TRAIN_573_4",
        "_index": "demo_chunking",
        "_score": 0.3,
        "_source": {
         "chunking_number": 4,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 考试分成三个独立的部分，在不同的日子进行。"
        }
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "Before rerank result"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": [
       {
        "_id": "TRAIN_573_12",
        "_index": "demo_chunking",
        "_score": 0.16666667,
        "_source": {
         "chunking_number": 12,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 故在随机答题的状况，所得分数的期望值为理论系考试以物理、化学与生物学三部分组成。"
        },
        "rerank_score": 0.98682701587677
       },
       {
        "_id": "TRAIN_573_5",
        "_index": "demo_chunking",
        "_score": 0.6111111,
        "_source": {
         "chunking_number": 5,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。"
        },
        "rerank_score": 0.9855902791023254
       },
       {
        "_id": "TRAIN_573_7",
        "_index": "demo_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 7,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。"
        },
        "rerank_score": 0.9750074148178101
       },
       {
        "_id": "TRAIN_573_0",
        "_index": "demo_chunking",
        "_score": 0.8333334,
        "_source": {
         "chunking_number": 0,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。"
        },
        "rerank_score": 0.9329694509506226
       },
       {
        "_id": "TRAIN_573_4",
        "_index": "demo_chunking",
        "_score": 0.3,
        "_source": {
         "chunking_number": 4,
         "document_id": "TRAIN_573",
         "text_field": "国际初中科学奥林匹克: 考试分成三个独立的部分，在不同的日子进行。"
        },
        "rerank_score": 0.7948662042617798
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "After rerank result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#下方演示：先全文、向量检索再进行rerank的使用方式\n",
    "def demo_rerank(query):\n",
    "    lindorm = Lindorm()\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    origin_result = lindorm.lindormSearch.rrf_search(query,  topk * 2)\n",
    "    display(JSON(origin_result[0:topk], expanded=True, root=\"Before rerank result\"))\n",
    "    texts = [item[\"_source\"][\"text_field\"] for item in origin_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    reranked_origin_result = lindorm.lindormAI.handler_reranker(origin_result, reranker_result, topk)\n",
    "    display(JSON(reranked_origin_result, expanded=True, root=\"After rerank result\"))\n",
    "    lindorm.close()\n",
    "    \n",
    "query=\"国际初中科学奥林匹克主要比赛科目\"    \n",
    "demo_rerank(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>国际初中科学奥林匹克的主要比赛科目包括物理、化学与生物学。这些科目构成了理论系考试和试验系考试的内容。其中，试验系考试由30题多项选择题组成，物理、化学与生物学\n",
       "各占10题。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>提示模版为:\n",
       "已知信息：\n",
       "国际初中科学奥林匹克: 故在随机答题的状况，所得分数的期望值为理论系考试以物理、化学与生物学三部分组成。\n",
       "国际初中科学奥林匹克: 此考试需要学生拥有科学（即物理、化学与生物学）的知识。\n",
       "国际初中科学奥林匹克: 试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。\n",
       "国际初中科学奥林匹克: 国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。\n",
       "国际初中科学奥林匹克: 考试分成三个独立的部分，在不同的日子进行。 \n",
       "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：国际初中科学奥林匹克主要比赛科目</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 下方演示：先进行全文向量混合检索，将混合检索的结果进行rerank，然后将问题以及检索结果一起prompt提交大模型\n",
    "def demo_chat_with_child_chunking(query):\n",
    "    lindorm = Lindorm()\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    search_result = lindorm.lindormSearch.rrf_search(query, topk * 2)\n",
    "    texts = [item[\"_source\"][\"text_field\"] for item in search_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    prompt_context = \"\\n\".join(item['chunk'] for item in reranker_result[0:topk])\n",
    "    ali_qwen = AliQwen()\n",
    "    prompt = ali_qwen.gen_prompt(query, prompt_context)\n",
    "    output_text = \"\"\n",
    "    for part in ali_qwen.chat_stream(prompt):\n",
    "        output_text = part \n",
    "        wrapped_text = wrap_text(output_text, 80)\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='color: red;'>{wrapped_text}</pre>\"))\n",
    "    \n",
    "    wrapped_text = wrap_text(prompt, 120)\n",
    "    display(HTML(f\"<pre>提示模版为:\\n{wrapped_text}</pre>\"))\n",
    "    lindorm.close()\n",
    "\n",
    "query=\"国际初中科学奥林匹克主要比赛科目\"  \n",
    "demo_chat_with_child_chunking(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>国际初中科学奥林匹克（IJSO）的主要比赛科目包括科学领域的三个部分，具体是：\n",
       "1. **物理**\n",
       "2. **化学**\n",
       "3. **生物学**\n",
       "这些科目涵盖在考试的三个独立部分中：试验系考试、理论系考试和实验系考试。学生需要在这三个科学领域具备相关知识来参加比赛。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>提示模版为:\n",
       "已知信息：\n",
       "国际初中科学奥林匹克（International Junior Science Olympiad，简称IJSO）是一项给予15岁或以下的学生参与的国际科学比赛。此比赛最先在2004年举办，然后一年举办一次。每一个国家／地区可以派出以6名学生\n",
       "及3名领队组成队伍参与赛事。这也是国际科学奥林匹克的其中之一。考试分成三个独立的部分，在不同的日子进行。此考试需要学生拥有科学（即物理、化学与生物学）的知识。以100分为满分。试验系考试由30题多项选择题组成，物理、化学与生物学各占10题。\n",
       "每题有4个选择。每答对一题得1分，每答错一题倒扣0.25分，弃权不扣分。这一部分以30分为满分。依照试验系考试的资料，答中题目的机率为P(C)，而答错题目的机率为P(E)，则formula_1　而　formula_2。故在随机答题的状况，所\n",
       "得分数的期望值为理论系考试以物理、化学与生物学三部分组成。以30分为满分。实验系考试必须以最多三人分成一小组进行，即每一个参赛单位可以分成最多两个小组。在同一小组的所有学生都会有相同的分数。以40分为满分。从第一届至第三届，实验系考试只有一\n",
       "题；而在第四届，实验系考试就分成四题。 \n",
       "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：国际初中科学奥林匹克主要比赛科目</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 下方演示：先进行全文向量混合检索，将混合检索的结果进行rerank，然后从父表中查询context字段，与问题一起prompt提交大模型回答\n",
    "def demo_chat_with_parent(query):\n",
    "    lindorm = Lindorm()\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    search_result = lindorm.lindormSearch.rrf_search(query, topk * 2)\n",
    "    texts = [item[\"_source\"][\"text_field\"] for item in search_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    reranked_origin_result = lindorm.lindormAI.handler_reranker(search_result, reranker_result, topk)\n",
    "    unique_document_ids = list(OrderedDict.fromkeys(item['_source']['document_id'] for item in reranked_origin_result))\n",
    "    contexts = []\n",
    "    for document_id in unique_document_ids:\n",
    "        contexts.append(lindorm.lindormSearch.get_parent_context(document_id=document_id))\n",
    "    prompt_context = \"\\n\".join(contexts)        \n",
    "    ali_qwen = AliQwen()\n",
    "    prompt = ali_qwen.gen_prompt(query, prompt_context)    \n",
    "    # stream\n",
    "    for part in ali_qwen.chat_stream(prompt):\n",
    "        output_text = part \n",
    "        wrapped_text = wrap_text(output_text, 80)\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='color: red;'>{wrapped_text}</pre>\"))\n",
    "    \n",
    "    wrapped_text = wrap_text(prompt, 120)\n",
    "    display(HTML(f\"<pre>提示模版为:\\n{wrapped_text}</pre>\")) \n",
    "    lindorm.close()\n",
    "    \n",
    "query=\"国际初中科学奥林匹克主要比赛科目\"  \n",
    "demo_chat_with_parent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
