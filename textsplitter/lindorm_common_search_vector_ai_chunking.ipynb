{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo说明\n",
    "利用Lindorm搜素引擎、向量引擎、AI引擎构建私域知识库场景问答。\n",
    "本demo比较偏向公共的场景，比如用户上传一个txt文档，便可以构建私域知识库问答。\n",
    "父表(demo_parent表)有一列是context，将其切分为多个chunking，写入子表（demo_chunking）的text_field字段。数据\n",
    "导入完成后便可进行近似检索，将检索的结果与用户问题进行prompt提交给大模型（可以选择提交chunking后的文本，还是父表中的context字段），便可以实现私域数据知识问答。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensearchpy import OpenSearch\n",
    "from opensearchpy.helpers import bulk\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from textsplitter import ChineseTextSplitter\n",
    "from ldconfig import Config\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm \n",
    "from dashscope import Generation\n",
    "from http import HTTPStatus\n",
    "from collections import OrderedDict\n",
    "from IPython.display import display, clear_output, HTML, JSON\n",
    "# 控制opensearch的日志输出级别，防止日志打爆\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.getLogger('opensearch').setLevel(logging.WARN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lindorm:\n",
    "    def __init__(self, index_name):\n",
    "        self.index_name = index_name\n",
    "        # embedding 模型名\n",
    "        self.embedding_model_name = \"bge_m3_model\"    \n",
    "        # rerank 模型名\n",
    "        self.reranker_model_name = \"rerank_bge_v2_m3\"\n",
    "        \n",
    "        self.lindormAI = self.LindormAI(self)\n",
    "        self.lindormSearch = self.LindormSearch(self)\n",
    "    \n",
    "    def close(self):\n",
    "        pass\n",
    "    \n",
    "    \"\"\"\n",
    "    使用Rest接口访问AI引擎\n",
    "    \"\"\"    \n",
    "    class LindormAI():\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            self.headers = {\n",
    "                \"Content-Type\": \"application/json; charset=utf-8\",\n",
    "                \"x-ld-ak\": Config.LD_USER,\n",
    "                \"x-ld-sk\": Config.LD_PASSWORD\n",
    "                }\n",
    "            \n",
    "        \"\"\"\n",
    "        查询当前model的列表\n",
    "        \"\"\"\n",
    "        def list_modes(self) -> list:\n",
    "            url = \"http://{}:{}/v1/ai/models/list\".format(Config.AI_HOST, Config.AI_PORT)\n",
    "            response = requests.get(url, headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"][\"models\"]\n",
    "        \n",
    "        def common_create_model(self, model_name, model_path, task, algorithm):\n",
    "            url = \"http://{}:{}/v1/ai/models/create\".format(Config.AI_HOST, int(Config.AI_PORT))\n",
    "            data = {\n",
    "                \"model_name\": model_name,\n",
    "                \"model_path\": model_path,\n",
    "                \"task\": task,\n",
    "                \"algorithm\": algorithm,\n",
    "                \"settings\": {\"instance_count\": \"2\"}\n",
    "            }\n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                print(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "        \n",
    "        def check_model_exists(self, model_name) -> list: \n",
    "            models = self.list_modes()\n",
    "            for model in models:\n",
    "                if model['name'] == model_name:\n",
    "                    return True\n",
    "            return False\n",
    "        \n",
    "        \"\"\"\n",
    "        创建embedding模型，目前推荐使用bge-m3模型即可\n",
    "        \"\"\"\n",
    "        def create_embedding_model(self):\n",
    "            if self.check_model_exists(self.parent.embedding_model_name):\n",
    "                print(\"Model {} exists, skip create\".format(self.parent.embedding_model_name))\n",
    "                return\n",
    "\n",
    "            self.common_create_model(self.parent.embedding_model_name, \n",
    "                                    \"huggingface://BAAI/bge-m3\",\n",
    "                                    \"FEATURE_EXTRACTION\",\n",
    "                                    \"BGE_M3\")\n",
    "          \n",
    "        \"\"\"\n",
    "        创建reranker模型，目前推荐使用 bge-reranker-v2-m3\n",
    "        \"\"\"\n",
    "        def create_reranker_model(self):\n",
    "            if self.check_model_exists(self.parent.reranker_model_name):\n",
    "                print(\"Model {} exists, skip create\".format(self.parent.reranker_model_name))\n",
    "                return\n",
    "            \n",
    "            self.common_create_model(self.parent.reranker_model_name,\n",
    "                                    \"huggingface://BAAI/bge-reranker-v2-m3\",\n",
    "                                    \"SEMANTIC_SIMILARITY\",\n",
    "                                    \"BGE_RERANKER_V2_M3\")\n",
    "        \n",
    "        \"\"\"\n",
    "        对输入的文本文本进行embedding成向量\n",
    "        \"\"\"\n",
    "        def text_embedding(self, input_text:str):\n",
    "            url = \"http://{}:{}/v1/ai/models/{}/infer\".format(Config.AI_HOST, \n",
    "                                                              Config.AI_PORT, \n",
    "                                                              self.parent.embedding_model_name)\n",
    "            input_text_utf8 = input_text.encode('utf-8').decode('utf-8')\n",
    "            data = {\n",
    "                \"input\": [input_text_utf8]\n",
    "            }\n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"][0]\n",
    "\n",
    "        \"\"\"\n",
    "        根据问题以及目前答案的候选集，对答案进行重新排序\n",
    "        * input_text: 输入的问题\n",
    "        * chunks: 答案列表\n",
    "        \"\"\"\n",
    "        def reranker(self, input_text:str,  chunks: List[str]):\n",
    "            url = \"http://{}:{}/v1/ai/models/{}/infer\".format(Config.AI_HOST,\n",
    "                                                              Config.AI_PORT, \n",
    "                                                              self.parent.reranker_model_name)        \n",
    "            data = {\n",
    "                \"input\": {\"query\": input_text, \"chunks\": chunks}\n",
    "            }\n",
    "            \n",
    "            response = requests.post(url, data=json.dumps(data), headers=self.headers)\n",
    "            json_response = response.json()\n",
    "            if response.status_code != 200 or json_response[\"success\"] is False:\n",
    "                raise Exception(\"http request failed, status code: {}\".format(json_response[\"msg\"]))\n",
    "            return json_response[\"data\"]\n",
    "        \n",
    "        \"\"\"\n",
    "        处理rerank之后的结果，如为每个json对象添加 rerank_score 字段标识为rerank之后的得分\n",
    "        \"\"\"\n",
    "        def handler_reranker(self, origin_result, reranker_result, topk):\n",
    "            reranked_origin_result = []\n",
    "            for score_item in reranker_result:\n",
    "                index = score_item['index']\n",
    "                if index < len(origin_result):\n",
    "                    original = origin_result[index]\n",
    "                    original['rerank_score'] = score_item['score']\n",
    "                    reranked_origin_result.append(original)\n",
    "            return reranked_origin_result[0:topk]\n",
    "            \n",
    "    \"\"\"\n",
    "    使用opensearch客户端访问搜索引擎\n",
    "    \"\"\"\n",
    "    class LindormSearch():\n",
    "        def __init__(self, parent):\n",
    "            self.parent = parent\n",
    "            # 主表名\n",
    "            self.parent_index= self.parent.index_name + \"_parent\"\n",
    "            # 子表名\n",
    "            self.chunking_index=self.parent.index_name + \"_chunking\"\n",
    "            \n",
    "            # 文本字段名\n",
    "            self.text_field = \"text_field\" \n",
    "            # 向量字段名\n",
    "            self.vector_field = \"vector_field\" \n",
    "            # 写入pipeline\n",
    "            self.write_pipeline = \"demo_write_embedding_pipeline\" \n",
    "            # 查询pipeline\n",
    "            self.search_pipeline = \"demo_search_embedding_pipeline\"\n",
    "            self.top_k = 5\n",
    "            self.client = None\n",
    "            try:\n",
    "                self.client = OpenSearch(\n",
    "                    hosts=[{\"host\": Config.SEARCH_HOST, \"port\": Config.SEARCH_PORT}],\n",
    "                    http_auth=(Config.LD_USER, Config.LD_PASSWORD),\n",
    "                    http_compress=False,\n",
    "                    use_ssl=False,\n",
    "                    timeout=60\n",
    "                )\n",
    "            except Exception as e:   \n",
    "                print(\"Connection search error\", e)\n",
    "                \n",
    "        \"\"\"\n",
    "        检查写入pipeline是否存在\n",
    "        \"\"\"\n",
    "        def check_write_pipeline_exists(self) -> bool:\n",
    "            try:\n",
    "                response = self.client.ingest.get_pipeline(id=self.write_pipeline)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                return False\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        检查搜索pipeline是否存在\n",
    "        \"\"\"\n",
    "        def check_knn_pipeline_exists(self) -> bool:\n",
    "            try:\n",
    "                response = self.client.search_pipeline.get(id=self.search_pipeline)\n",
    "                print(response)\n",
    "                return True\n",
    "            except Exception as e:\n",
    "                return False\n",
    "        \n",
    "        \"\"\"\n",
    "        创建pipleline,搜索内部自动对text字段调用ai引擎进行embedding,写入vector_field 字段\n",
    "        \"\"\"\n",
    "        def create_write_pipeline(self):\n",
    "            print(self.parent.embedding_model_name)\n",
    "            if self.check_write_pipeline_exists():\n",
    "                print(\"Pipeline {} exists\".format(self.write_pipeline))\n",
    "                # 如果pipeline已经存在，目前策略是跳过，如果是需要调整参数重新创建，则注释掉下方的return\n",
    "                return\n",
    "            \n",
    "            inner_ai_host = Config.AI_HOST\n",
    "            if \"-pub\" in inner_ai_host:\n",
    "                inner_ai_host = inner_ai_host.replace(\"-pub\", \"-vpc\")\n",
    "                \n",
    "            pipeline = {\n",
    "                \"description\": \"demo_chunking pipeline\",\n",
    "                \"processors\": [\n",
    "                    {\n",
    "                        \"text-embedding\": {\n",
    "                            \"inputFields\": [self.text_field],   \n",
    "                            \"outputFields\": [self.vector_field],\n",
    "                            \"userName\": Config.LD_USER,\n",
    "                            \"password\": Config.LD_PASSWORD,\n",
    "                            \"url\": \"http://{}:{}\".format(inner_ai_host, int(Config.AI_PORT)),\n",
    "                            \"modeName\": self.parent.embedding_model_name\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }    \n",
    "            try:\n",
    "                response = self.client.ingest.put_pipeline(id=self.write_pipeline, body=pipeline)\n",
    "                print(\"Create pipeline success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create pipeline errr \", e)   \n",
    "        \n",
    "        \"\"\"\n",
    "        创建knn时自动pipleline\n",
    "        \"\"\"\n",
    "        def create_knnsearch_pipeline(self):\n",
    "            if self.check_knn_pipeline_exists():\n",
    "                print(\"Pipeline {} exists\".format(self.search_pipeline))\n",
    "                # 如果pipeline已经存在，目前策略是跳过，如果是需要调整参数重新创建，则注释掉下方的return\n",
    "                return\n",
    "            inner_ai_host = Config.AI_HOST\n",
    "            if \"-pub\" in inner_ai_host:\n",
    "                inner_ai_host = inner_ai_host.replace(\"-pub\", \"-vpc\")\n",
    "\n",
    "            pipeline = {\n",
    "                \"request_processors\": [\n",
    "                    {\n",
    "                        \"text-embedding\": {\n",
    "                            \"tag\": \"auto-query-embedding\",\n",
    "                            \"description\": \"Auto query embedding\",\n",
    "                            \"model_config\": {\n",
    "                                \"inputFields\": [self.text_field],\n",
    "                                \"outputFields\": [self.vector_field],\n",
    "                                \"userName\": Config.LD_USER,\n",
    "                                \"password\": Config.LD_PASSWORD,\n",
    "                                \"url\": \"http://{}:{}\".format(inner_ai_host, int(Config.AI_PORT)),\n",
    "                                \"modeName\": self.parent.embedding_model_name\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            try:\n",
    "                response = self.client.search_pipeline.put(id=self.search_pipeline, body=pipeline)\n",
    "                print(\"Create pipeline success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create pipeline errr \", e)\n",
    "                \n",
    "        def create_parent_index(self):\n",
    "            if self.client.indices.exists(index=self.parent_index):\n",
    "                print(\"Index {} exists\".format(self.parent_index))\n",
    "                return\n",
    "            \n",
    "            index_body = {\n",
    "                \"settings\": {\n",
    "                    \"index\": {\n",
    "                        \"number_of_shards\": 4,\n",
    "                    }\n",
    "                },\n",
    "                \"mappings\": {\n",
    "                    \"properties\": {\n",
    "                        \"document_id\": {\n",
    "                            \"type\": \"keyword\"\n",
    "                        },\n",
    "                        \"context\": {\n",
    "                            \"type\": \"text\", \n",
    "                            \"analyzer\": \"ik_max_word\", \n",
    "                            \"index\":False,\n",
    "                            \"doc_values\":False\n",
    "                        },\n",
    "                        \"metadata\": {\n",
    "                            \"type\": \"object\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                response = self.client.indices.create(index=self.parent_index, body=index_body)\n",
    "                print(\"Create parent index success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create index errr \", e)\n",
    "        \n",
    "        def create_chunking_index(self):\n",
    "            if self.client.indices.exists(index=self.chunking_index):\n",
    "                print(\"Index {} exists\".format(self.chunking_index))\n",
    "                return\n",
    "            \n",
    "            # 本文演示的 bge-m3 模型编码后的维度为1024维，因此向量dimension设置为1024\n",
    "            index_body = {\n",
    "                \"settings\": {\n",
    "                    \"index\": {\n",
    "                        \"number_of_shards\": 4,\n",
    "                        \"knn\": True,\n",
    "                        \"default_pipeline\": self.write_pipeline,\n",
    "                        \"search.default_pipeline\": self.search_pipeline\n",
    "                    }\n",
    "                },\n",
    "                \"mappings\": {\n",
    "                    \"_source\": {\n",
    "                        \"excludes\": [self.vector_field]\n",
    "                    },\n",
    "                    \"properties\": {\n",
    "                        \"document_id\": {\n",
    "                            \"type\": \"keyword\"\n",
    "                        },\n",
    "                        self.text_field: {\n",
    "                            \"type\": \"text\",\n",
    "                            \"analyzer\": \"ik_max_word\", \n",
    "                        },\n",
    "                        self.vector_field: {\n",
    "                            \"type\": \"knn_vector\",\n",
    "                            \"dimension\": 1024,\n",
    "                            \"data_type\": \"float\",\n",
    "                            \"method\": {\n",
    "                                \"engine\": \"lvector\",\n",
    "                                \"name\": \"hnsw\",\n",
    "                                \"space_type\": \"l2\",\n",
    "                                \"parameters\": {\n",
    "                                    \"m\": 24,\n",
    "                                    \"ef_construction\": 500\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        \"chunking_number\": {\n",
    "                            \"type\": \"integer\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            try:\n",
    "                response = self.client.indices.create(index=self.chunking_index, body=index_body)\n",
    "                print(\"Create chunking index success\", response)\n",
    "            except Exception as e:\n",
    "                print(\"Create index errr \", e)\n",
    "        \n",
    "        def write_parent(self, data):\n",
    "            self.client.index(index=self.parent_index, id = data['document_id'], body=data)\n",
    "            \n",
    "        def write_chunking(self, datas):\n",
    "            # 写入 text_field 字段时，会自动embedding为向量写入 vector_field 字段\n",
    "            def gen():\n",
    "                for data in datas:\n",
    "                    yield {\n",
    "                        \"_op_type\": \"index\",\n",
    "                        \"_index\": self.chunking_index,\n",
    "                        \"_id\": data['document_id'] + \"_\" + str(data['chunking_position']),\n",
    "                        \"document_id\": data['document_id'],\n",
    "                        \"text_field\": data['text_field'],\n",
    "                        \"chunking_number\": data['chunking_position'],\n",
    "                    }\n",
    "            (_, errors) = bulk(\n",
    "            self.client, gen(), chunk_size=500, max_retries=2, request_timeout=120)\n",
    "        \n",
    "        def get_parent_context(self, document_id):\n",
    "            res = self.client.get(index=self.parent_index, id=document_id)\n",
    "            return res['_source']['context']\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        纯文本检索\n",
    "        \"\"\"\n",
    "        def text_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_number\",  self.text_field],\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        self.text_field: text_query\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "            res = self.client.search(index=self.chunking_index, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "        \"\"\"\n",
    "        纯向量检索，用例中使用查询自动embedding功能\n",
    "        \"\"\"\n",
    "        def vector_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_number\",  self.text_field],\n",
    "                \"query\":{\n",
    "                    \"knn\": {\n",
    "                        self.vector_field: {\n",
    "                            \"query_text\": text_query,\n",
    "                            \"k\": k\n",
    "                        }                      \n",
    "                    }\n",
    "                },\n",
    "                \"ext\": {\"lvector\":{\"ef_search\": \"200\"}}\n",
    "            }\n",
    "            res = self.client.search(index=self.chunking_index, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "        \"\"\"\n",
    "        全文、向量融合检索，用例中使用查询自动embedding功能\n",
    "        \"\"\"\n",
    "        def rrf_search(self, text_query, k = int(Config.SEARCH_TOP_K)):\n",
    "            query_body = {\n",
    "                \"size\": k,\n",
    "                \"_source\": [\"document_id\", \"chunking_number\", \"text_field\"],\n",
    "                \"query\": {\n",
    "                    \"knn\": {\n",
    "                    self.vector_field: { \n",
    "                        \"query_text\": text_query,\n",
    "                        \"filter\": {\n",
    "                            \"match\": {\n",
    "                                self.text_field: text_query,\n",
    "                            }\n",
    "                        },\n",
    "                        \"k\": k\n",
    "                      }\n",
    "                    }\n",
    "                },\n",
    "                \"ext\": {\"lvector\": {\n",
    "                    \"hybrid_search_type\": \"filter_rrf\", \n",
    "                    \"rrf_rank_constant\": \"1\",\n",
    "                    \"ef_search\": \"200\"\n",
    "                }}\n",
    "            }\n",
    "            res = self.client.search(index=self.chunking_index, body=query_body)\n",
    "            return res['hits']['hits']\n",
    "        \n",
    "\n",
    "\"\"\"\n",
    "使用api_key访问通义前问的方式\n",
    "\"\"\"\n",
    "# reference: https://help.aliyun.com/zh/dashscope/developer-reference/qwen-api\n",
    "class AliQwen():\n",
    "    def __init__(self):\n",
    "        self.api_key = Config.DASHSCOPE_API_KEY\n",
    "        self.model_name = \"qwen-plus\"\n",
    "        self.PROMPT_TEMPLATE = \"\"\"已知信息：\n",
    "{context} \n",
    "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：{question}\"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    非流式对话大模型\n",
    "    \"\"\"\n",
    "    def chat(self, prompt: str):\n",
    "        response = Generation.call(model=self.model_name, prompt=prompt, stream=False, api_key=self.api_key)\n",
    "        if response.status_code == HTTPStatus.OK:\n",
    "            return response.output.text\n",
    "        else:\n",
    "            raise Exception(response.message)\n",
    "    \n",
    "    \"\"\"\n",
    "    流式对话大模型\n",
    "    \"\"\"\n",
    "    def chat_stream(self, prompt: str):\n",
    "        responses = Generation.call(model=self.model_name, prompt=prompt, stream=True, api_key=self.api_key)\n",
    "        for response in responses:\n",
    "            if response.status_code == HTTPStatus.OK:\n",
    "                yield response.output.text\n",
    "            else:\n",
    "                raise Exception(response.message)\n",
    "    \n",
    "    \"\"\"\n",
    "    问题与相关提示一起组装\n",
    "    \"\"\"\n",
    "    def gen_prompt(self, query: str, context: str):\n",
    "        return self.PROMPT_TEMPLATE.replace(\"{question}\", query).replace(\"{context}\", context)\n",
    "\n",
    "\"\"\"\n",
    "打印工具\n",
    "\"\"\"\n",
    "def wrap_text(text, width):\n",
    "    wrapped_lines = []\n",
    "    for line in text.splitlines():\n",
    "            wrapped_lines.extend([line[i:i + width] for i in range(0, len(line), width)])\n",
    "    return \"\\n\".join(wrapped_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model bge_m3_model exists, skip create\n",
      "Model rerank_bge_v2_m3 exists, skip create\n"
     ]
    }
   ],
   "source": [
    "index_name = \"test\"\n",
    "lindorm = Lindorm(index_name)\n",
    "def ai_model():\n",
    "    # AI: 创建AI embedding 模型\n",
    "    lindorm.lindormAI.create_embedding_model()\n",
    "    # AI: 创建AI reranker 模型\n",
    "    lindorm.lindormAI.create_reranker_model()\n",
    "ai_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models:  [\n",
      "    {\n",
      "        \"name\": \"rerank_bge_v2_m3\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2025-03-10T20:01:26.002+08:00\",\n",
      "        \"update_time\": \"2025-03-10T20:03:28.997+08:00\"\n",
      "    },\n",
      "    {\n",
      "        \"name\": \"bge_m3_model\",\n",
      "        \"status\": \"READY\",\n",
      "        \"sql_function\": \"ai_infer\",\n",
      "        \"created_time\": \"2025-03-10T20:01:25.598+08:00\",\n",
      "        \"update_time\": \"2025-03-10T20:02:58.952+08:00\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "index_name = \"test\"\n",
    "lindorm = Lindorm(index_name)\n",
    "def ai_check_model_ready():\n",
    "    models = lindorm.lindormAI.list_modes()\n",
    "    # 等待部署的status为READY后，进行下一步\n",
    "    print(\"models: \", json.dumps(models, indent=4, ensure_ascii=False))\n",
    "    \n",
    "ai_check_model_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bge_m3_model\n",
      "Pipeline demo_write_embedding_pipeline exists\n",
      "{'demo_search_embedding_pipeline': {'request_processors': [{'text-embedding': {'tag': 'auto-query-embedding', 'description': 'Auto query embedding', 'model_config': {'inputFields': ['text_field'], 'outputFields': ['vector_field'], 'userName': 'root', 'password': 'eUxmlnqBlUze', 'url': 'http://ld-2zeq6izld90k65s3e-proxy-ai-vpc.lindorm.aliyuncs.com:9002', 'modeName': 'bge_m3_model'}}}]}}\n",
      "Pipeline demo_search_embedding_pipeline exists\n",
      "Index test_parent exists\n",
      "Index test_chunking exists\n"
     ]
    }
   ],
   "source": [
    "index_name = \"test\"\n",
    "lindorm = Lindorm(index_name)\n",
    "def search_init():\n",
    "    # Search: 创建写入pipeline\n",
    "    lindorm.lindormSearch.create_write_pipeline()\n",
    "    # # Search: 创建搜索pipeline\n",
    "    lindorm.lindormSearch.create_knnsearch_pipeline()\n",
    "    # # Search: 创建主表\n",
    "    lindorm.lindormSearch.create_parent_index()\n",
    "    # # Search: 创建子表\n",
    "    lindorm.lindormSearch.create_chunking_index()\n",
    "    \n",
    "search_init()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a33828118be438aa2f9bd53517ba990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.txt', description='Upload'), Button(description='上传文件', style=But…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 上传本地txt文件， 先点击Upload选择文件，再点击上传文件\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# 指定保存文件的目录\n",
    "save_directory = \"./data\"  # 替换为你希望保存文件的目录\n",
    "\n",
    "# 如果目录不存在，则创建目录\n",
    "if not os.path.exists(save_directory):\n",
    "    os.makedirs(save_directory)\n",
    "\n",
    "# 创建文件上传小部件\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.txt',  # 只接受 .txt 文件\n",
    "    multiple=False  # 只允许上传一个文件\n",
    ")\n",
    "\n",
    "# 创建一个按钮用于触发文件上传\n",
    "upload_button = widgets.Button(description=\"上传文件\")\n",
    "\n",
    "# 创建一个输出区域用于显示结果\n",
    "output = widgets.Output()\n",
    "\n",
    "# 定义按钮点击事件的回调函数\n",
    "def on_upload_button_click(button):\n",
    "    with output:\n",
    "        output.clear_output()  # 清空之前的输出\n",
    "        if uploader.value:  # 检查是否有文件上传\n",
    "            for file_info in uploader.value:\n",
    "                # 获取文件名\n",
    "                file_name = file_info['name']\n",
    "                file_content = file_info['content']  # 获取文件内容（字节形式）\n",
    "\n",
    "                # 构造保存路径\n",
    "                save_path = os.path.join(save_directory, file_name)\n",
    "                \n",
    "                # 将文件内容保存到指定目录\n",
    "                with open(save_path, 'wb') as f:\n",
    "                    f.write(file_content)\n",
    "                \n",
    "                print(f\"文件已成功保存到：{save_path}\")\n",
    "        else:\n",
    "            print(\"未检测到上传的文件，请重新上传。\")\n",
    "\n",
    "# 绑定按钮点击事件\n",
    "upload_button.on_click(on_upload_button_click)\n",
    "\n",
    "# 显示组件\n",
    "display(widgets.VBox([uploader, upload_button, output]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Docs: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [00:06<00:00,  3.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# 写入数据\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "lindorm = Lindorm(\"test\")\n",
    "\n",
    "def data_loader(filepath, parent_chunk_size, child_chunk_size):\n",
    "    loader = TextLoader(filepath, autodetect_encoding=True)\n",
    "    parent_split = RecursiveCharacterTextSplitter(chunk_size=parent_chunk_size, chunk_overlap=0)\n",
    "    docs = loader.load_and_split(parent_split)\n",
    "    child_splitter = RecursiveCharacterTextSplitter(chunk_size=child_chunk_size, chunk_overlap=0)\n",
    "    for index, doc in tqdm(enumerate(docs), total=len(docs), desc=\"Processing Docs\"):\n",
    "        parent_doc_id = doc.metadata['source'] + '_parent_' + str(index)\n",
    "        write_data = {\n",
    "            \"document_id\": parent_doc_id,\n",
    "            \"context\": doc.page_content,\n",
    "            \"metadata\": doc.metadata\n",
    "        }\n",
    "        lindorm.lindormSearch.write_parent(write_data)\n",
    "        chunkings = child_splitter.split_text(text=doc.page_content)\n",
    "        write_chunkings = []\n",
    "        for index, chunking in enumerate(chunkings):\n",
    "            chunking_data = {\n",
    "                    \"document_id\": parent_doc_id,\n",
    "                    \"text_field\": chunking,\n",
    "                    \"chunking_position\": index\n",
    "                }\n",
    "            write_chunkings.append(chunking_data)\n",
    "        lindorm.lindormSearch.write_chunking(write_chunkings)\n",
    "            \n",
    "filepath = \"./data/baike_documents.txt\"\n",
    "data_loader(filepath, 1000, 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "_id": "./data/baike_documents.txt_parent_11_1",
        "_index": "test_chunking",
        "_score": 0.8333334,
        "_source": {
         "chunking_number": 1,
         "document_id": "./data/baike_documents.txt_parent_11",
         "text_field": "在意象的使用上，辛弃疾也自有特点。他一般很少采用传统词作中常见的兰柳花草及红粉佳人为点缀：与所要表达的悲凉雄壮的情感基调相吻合，在他的笔下所描绘的自然景物，多有一种奔腾耸峙、不可一世的气派。如“峡束苍江对起，过危楼、欲飞还敛”（《水龙吟》），“谁信天峰飞堕地，傍湖千丈开青壁”（《满江红》）：他所采摭的历史人物，也多属于奇伟英豪、宕放不羁，或慷慨悲凉的类型，如“射虎山横一骑，裂石响惊弦”的李广（《八声甘州》），“金戈铁马，气吞万里如虎”的刘裕（《永遇乐》），“年少万兜鍪，坐断东南战未休”的孙权（"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_10_2",
        "_index": "test_chunking",
        "_score": 0.5,
        "_source": {
         "chunking_number": 2,
         "document_id": "./data/baike_documents.txt_parent_10",
         "text_field": "辛弃疾的独特成就是他创造了一种恢宏苍茫和阔大的词境，如《水龙吟·登建康赏心亭》。与辛词雄浑苍茫的意境相对应的是其意象的壮观飞动与充满生命的活力。这方面最成功、最得心应手的是他笔下的高大的抒情主人公形象，如《贺新郎·同父见和再用韵答之》。同时他的婉约词也写得独到精致、典雅妩媚。如《摸鱼儿·更能消几番风雨》。 [12]"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_12_4",
        "_index": "test_chunking",
        "_score": 0.33333334,
        "_source": {
         "chunking_number": 4,
         "document_id": "./data/baike_documents.txt_parent_12",
         "text_field": "此外，其描写农村景物和反映农家生活的作品，如《清平乐·村居》《西江月·夜行黄沙道中》《玉楼春·三三两两谁家女》等，都富有生活气息，给人以清新之感。其抒情小词，如《丑奴儿·书博山道中壁》《青玉案·元夕》等，写得含蓄蕴藉，言短意长。辛词继承了苏轼豪放词风和南宋初期爱国词人的战斗传统，进一步开拓了词的境界，扩大了词的题材，几乎达到无事无意不可入词的地步，又创造性地融汇了诗歌、散文、辞赋等各种文学形式的优点，丰富了词的表现手法，形成了辛词的独特风格。 [12]"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_22_4",
        "_index": "test_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 4,
         "document_id": "./data/baike_documents.txt_parent_22",
         "text_field": "在辛弃疾出帅淮军时，陈亮正处于穷困潦倒的绝境。他前往治所拜访辛弃疾，与他谈论天下大事。酒酣之际，辛弃疾畅谈宋金之间的利害，“南（宋）之可以并北（金）者，如此。北之可以并南者，如此”；还提及钱塘（临安）并非帝王所居之地，如果敌人“断牛头之山，天下无援兵；决西湖之水，（临安）满城皆鱼鳖”。饮毕，辛弃疾邀请陈亮住在自己的屋子里。陈亮半辗转反侧，思量道：“辛弃疾平素慎重寡言，醒来后一定会后悔自己的失言，将要杀我灭口。”于是盗走他的骏马逃走。一个多月后，陈亮主动致信辛弃疾，求借十万缗以接济，辛弃疾也如数"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_0_3",
        "_index": "test_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 3,
         "document_id": "./data/baike_documents.txt_parent_0",
         "text_field": "辛弃疾一生以恢复为志，以功业自许，却命运多舛，壮志难酬。但他始终没有动摇恢复中原的信念，而是把满腔激情和对国家兴亡、民族命运的关切、忧虑，全部寄寓于词作之中。其词艺术风格多样，以豪放为主，风格沉雄豪迈又不乏细腻柔媚之处，题材广阔又善化用典故入词，抒写力图恢复国家统一的爱国热情，倾诉壮志难酬的悲愤，对当时执政者的屈辱求和颇多谴责，也有不少吟咏祖国河山的作品。 [4] [68]有《稼轩长短句》等传世。今人辑有《辛稼轩诗文钞存》。"
        }
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "rrf_search_result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 向量 + 全文融合检索\n",
    "\n",
    "lindorm = Lindorm(\"test\")\n",
    "def demo_rrf_search(query):\n",
    "    results = lindorm.lindormSearch.rrf_search(query)\n",
    "    display(JSON(results, expanded=True, root=\"rrf_search_result\"))\n",
    "    lindorm.close()\n",
    "    \n",
    "query=\"辛弃疾诗歌特点\"    \n",
    "demo_rrf_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": [
       {
        "_id": "./data/baike_documents.txt_parent_11_1",
        "_index": "test_chunking",
        "_score": 0.8333334,
        "_source": {
         "chunking_number": 1,
         "document_id": "./data/baike_documents.txt_parent_11",
         "text_field": "在意象的使用上，辛弃疾也自有特点。他一般很少采用传统词作中常见的兰柳花草及红粉佳人为点缀：与所要表达的悲凉雄壮的情感基调相吻合，在他的笔下所描绘的自然景物，多有一种奔腾耸峙、不可一世的气派。如“峡束苍江对起，过危楼、欲飞还敛”（《水龙吟》），“谁信天峰飞堕地，傍湖千丈开青壁”（《满江红》）：他所采摭的历史人物，也多属于奇伟英豪、宕放不羁，或慷慨悲凉的类型，如“射虎山横一骑，裂石响惊弦”的李广（《八声甘州》），“金戈铁马，气吞万里如虎”的刘裕（《永遇乐》），“年少万兜鍪，坐断东南战未休”的孙权（"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_10_2",
        "_index": "test_chunking",
        "_score": 0.5,
        "_source": {
         "chunking_number": 2,
         "document_id": "./data/baike_documents.txt_parent_10",
         "text_field": "辛弃疾的独特成就是他创造了一种恢宏苍茫和阔大的词境，如《水龙吟·登建康赏心亭》。与辛词雄浑苍茫的意境相对应的是其意象的壮观飞动与充满生命的活力。这方面最成功、最得心应手的是他笔下的高大的抒情主人公形象，如《贺新郎·同父见和再用韵答之》。同时他的婉约词也写得独到精致、典雅妩媚。如《摸鱼儿·更能消几番风雨》。 [12]"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_12_4",
        "_index": "test_chunking",
        "_score": 0.4761905,
        "_source": {
         "chunking_number": 4,
         "document_id": "./data/baike_documents.txt_parent_12",
         "text_field": "此外，其描写农村景物和反映农家生活的作品，如《清平乐·村居》《西江月·夜行黄沙道中》《玉楼春·三三两两谁家女》等，都富有生活气息，给人以清新之感。其抒情小词，如《丑奴儿·书博山道中壁》《青玉案·元夕》等，写得含蓄蕴藉，言短意长。辛词继承了苏轼豪放词风和南宋初期爱国词人的战斗传统，进一步开拓了词的境界，扩大了词的题材，几乎达到无事无意不可入词的地步，又创造性地融汇了诗歌、散文、辞赋等各种文学形式的优点，丰富了词的表现手法，形成了辛词的独特风格。 [12]"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_22_4",
        "_index": "test_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 4,
         "document_id": "./data/baike_documents.txt_parent_22",
         "text_field": "在辛弃疾出帅淮军时，陈亮正处于穷困潦倒的绝境。他前往治所拜访辛弃疾，与他谈论天下大事。酒酣之际，辛弃疾畅谈宋金之间的利害，“南（宋）之可以并北（金）者，如此。北之可以并南者，如此”；还提及钱塘（临安）并非帝王所居之地，如果敌人“断牛头之山，天下无援兵；决西湖之水，（临安）满城皆鱼鳖”。饮毕，辛弃疾邀请陈亮住在自己的屋子里。陈亮半辗转反侧，思量道：“辛弃疾平素慎重寡言，醒来后一定会后悔自己的失言，将要杀我灭口。”于是盗走他的骏马逃走。一个多月后，陈亮主动致信辛弃疾，求借十万缗以接济，辛弃疾也如数"
        }
       },
       {
        "_id": "./data/baike_documents.txt_parent_0_3",
        "_index": "test_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 3,
         "document_id": "./data/baike_documents.txt_parent_0",
         "text_field": "辛弃疾一生以恢复为志，以功业自许，却命运多舛，壮志难酬。但他始终没有动摇恢复中原的信念，而是把满腔激情和对国家兴亡、民族命运的关切、忧虑，全部寄寓于词作之中。其词艺术风格多样，以豪放为主，风格沉雄豪迈又不乏细腻柔媚之处，题材广阔又善化用典故入词，抒写力图恢复国家统一的爱国热情，倾诉壮志难酬的悲愤，对当时执政者的屈辱求和颇多谴责，也有不少吟咏祖国河山的作品。 [4] [68]有《稼轩长短句》等传世。今人辑有《辛稼轩诗文钞存》。"
        }
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "Before rerank result"
      }
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": [
       {
        "_id": "./data/baike_documents.txt_parent_11_1",
        "_index": "test_chunking",
        "_score": 0.8333334,
        "_source": {
         "chunking_number": 1,
         "document_id": "./data/baike_documents.txt_parent_11",
         "text_field": "在意象的使用上，辛弃疾也自有特点。他一般很少采用传统词作中常见的兰柳花草及红粉佳人为点缀：与所要表达的悲凉雄壮的情感基调相吻合，在他的笔下所描绘的自然景物，多有一种奔腾耸峙、不可一世的气派。如“峡束苍江对起，过危楼、欲飞还敛”（《水龙吟》），“谁信天峰飞堕地，傍湖千丈开青壁”（《满江红》）：他所采摭的历史人物，也多属于奇伟英豪、宕放不羁，或慷慨悲凉的类型，如“射虎山横一骑，裂石响惊弦”的李广（《八声甘州》），“金戈铁马，气吞万里如虎”的刘裕（《永遇乐》），“年少万兜鍪，坐断东南战未休”的孙权（"
        },
        "rerank_score": 0.9945662021636963
       },
       {
        "_id": "./data/baike_documents.txt_parent_0_3",
        "_index": "test_chunking",
        "_score": 0.25,
        "_source": {
         "chunking_number": 3,
         "document_id": "./data/baike_documents.txt_parent_0",
         "text_field": "辛弃疾一生以恢复为志，以功业自许，却命运多舛，壮志难酬。但他始终没有动摇恢复中原的信念，而是把满腔激情和对国家兴亡、民族命运的关切、忧虑，全部寄寓于词作之中。其词艺术风格多样，以豪放为主，风格沉雄豪迈又不乏细腻柔媚之处，题材广阔又善化用典故入词，抒写力图恢复国家统一的爱国热情，倾诉壮志难酬的悲愤，对当时执政者的屈辱求和颇多谴责，也有不少吟咏祖国河山的作品。 [4] [68]有《稼轩长短句》等传世。今人辑有《辛稼轩诗文钞存》。"
        },
        "rerank_score": 0.9890376925468445
       },
       {
        "_id": "./data/baike_documents.txt_parent_13_4",
        "_index": "test_chunking",
        "_score": 0.2,
        "_source": {
         "chunking_number": 4,
         "document_id": "./data/baike_documents.txt_parent_13",
         "text_field": "辛弃疾的诗，据辛启泰所辑《稼轩集抄存》收诗111首。邓广铭辑校《辛稼轩诗文抄存》清除误收，增补遗漏，得诗124首。其后，孔凡礼的《辛稼轩诗词补辑》又新补诗19首。现存辛诗，共133首。辛诗从各个不同的侧面，反映了作者的生活和思想情感，可与其词相证，其中《送别湖南部曲》，自写政治遭遇，可与《鹧鸪天·壮岁旌旗拥万夫》对读；“有时思到难思处，拍碎栏干人不知”（《鹤鸣亭绝句》），感叹英雄失意，也与《水龙吟·登建康赏心亭》合拍，而“竹杖芒鞋看瀑回，暮年筋力倦崔嵬”《同杜叔高祝彦集观天保庵瀑布主人留饮两日"
        },
        "rerank_score": 0.9675906896591187
       },
       {
        "_id": "./data/baike_documents.txt_parent_7_0",
        "_index": "test_chunking",
        "_score": 0.16666667,
        "_source": {
         "chunking_number": 0,
         "document_id": "./data/baike_documents.txt_parent_7",
         "text_field": "辛弃疾词具有强烈的爱国思想和战斗精神。辛词的爱国思想与战斗精神首先表现在他对被分裂的北方的怀念和对抗金斗争的赞扬上。他词里不但经常出现“西北有神州”“西北是长安”等句子，还强烈表现他不能忍受南北分裂的局面。他在《贺新郎·用前韵送杜叔高》词中说：“起望衣冠神州路，白日销残战骨，叹夷甫诸人清绝。夜半狂歌悲风起，听铮铮阵马檐间铁，南共北，正分裂。”比较突出地表现这种思想。他青年时期曾直接参加北方人民的抗金斗争后来在词里还经常想起这种“马作的卢飞快，弓如霹雳弦惊”（《破阵子·为陈同甫赋壮词以寄之》），“"
        },
        "rerank_score": 0.9602543115615845
       },
       {
        "_id": "./data/baike_documents.txt_parent_10_2",
        "_index": "test_chunking",
        "_score": 0.5,
        "_source": {
         "chunking_number": 2,
         "document_id": "./data/baike_documents.txt_parent_10",
         "text_field": "辛弃疾的独特成就是他创造了一种恢宏苍茫和阔大的词境，如《水龙吟·登建康赏心亭》。与辛词雄浑苍茫的意境相对应的是其意象的壮观飞动与充满生命的活力。这方面最成功、最得心应手的是他笔下的高大的抒情主人公形象，如《贺新郎·同父见和再用韵答之》。同时他的婉约词也写得独到精致、典雅妩媚。如《摸鱼儿·更能消几番风雨》。 [12]"
        },
        "rerank_score": 0.95743727684021
       }
      ],
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "metadata": {
      "application/json": {
       "expanded": true,
       "root": "After rerank result"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 向量 + 全文融合检索，之后再对结果进行rerank\n",
    "lindorm = Lindorm(\"test\")\n",
    "def demo_rerank(query):\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    origin_result = lindorm.lindormSearch.rrf_search(query,  topk * 2)\n",
    "    display(JSON(origin_result[0:topk], expanded=True, root=\"Before rerank result\"))\n",
    "    texts = [item[\"_source\"][\"text_field\"] for item in origin_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    reranked_origin_result = lindorm.lindormAI.handler_reranker(origin_result, reranker_result, topk)\n",
    "    display(JSON(reranked_origin_result, expanded=True, root=\"After rerank result\"))\n",
    "    lindorm.close()\n",
    "    \n",
    "query=\"辛弃疾诗歌特点\"\n",
    "demo_rerank(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>根据已知信息，辛弃疾的诗歌特点可以从以下几个方面来概括：\n",
       "1. **反映生活和思想情感**：辛弃疾的诗从各个不同的侧面反映了作者的生活和思想情感，可以与其词作相互印证。例如，《送别湖南部曲》自写政治遭遇，与《鹧鸪天·壮\n",
       "岁旌旗拥万夫》相呼应；“有时思到难思处，拍碎栏干人不知”（《鹤鸣亭绝句》）感叹英雄失意，也与《水龙吟·登建康赏心亭》合拍。\n",
       "2. **抒发个人抱负和政治理想**：辛弃疾一生以恢复中原为志，以功业自许，其诗歌中常常表达出对国家兴亡、民族命运的关切和忧虑，以及对壮志难酬的悲愤。如“竹杖芒\n",
       "鞋看瀑回，暮年筋力倦崔嵬”（《同杜叔高祝彦集观天保庵瀑布主人留饮两日》），表现了他晚年的心境。\n",
       "3. **数量与版本**：据辛启泰所辑《稼轩集抄存》收诗111首，邓广铭辑校《辛稼轩诗文抄存》清除误收，增补遗漏，得诗124首。孔凡礼的《辛稼轩诗词补辑》又新补\n",
       "诗19首。现存辛诗共133首。\n",
       "4. **风格多样**：辛弃疾的诗歌风格多样，既有豪放的一面，也有婉约的一面。他的诗作不仅展现了他对祖国河山的热爱，还体现了他对历史人物的崇敬和对现实社会的批判\n",
       "。\n",
       "综上所述，辛弃疾的诗歌以其独特的艺术魅力和个人风格，成为中国文学宝库中的重要组成部分。</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre>提示模版为:\n",
       "已知信息：\n",
       "在意象的使用上，辛弃疾也自有特点。他一般很少采用传统词作中常见的兰柳花草及红粉佳人为点缀：与所要表达的悲凉雄壮的情感基调相吻合，在他的笔下所描绘的自然景物，多有一种奔腾耸峙、不可一世的气派。如“峡束苍江对起，过危楼、欲飞还敛”（《水龙吟》）\n",
       "，“谁信天峰飞堕地，傍湖千丈开青壁”（《满江红》）：他所采摭的历史人物，也多属于奇伟英豪、宕放不羁，或慷慨悲凉的类型，如“射虎山横一骑，裂石响惊弦”的李广（《八声甘州》），“金戈铁马，气吞万里如虎”的刘裕（《永遇乐》），“年少万兜鍪，坐断东\n",
       "南战未休”的孙权（\n",
       "辛弃疾一生以恢复为志，以功业自许，却命运多舛，壮志难酬。但他始终没有动摇恢复中原的信念，而是把满腔激情和对国家兴亡、民族命运的关切、忧虑，全部寄寓于词作之中。其词艺术风格多样，以豪放为主，风格沉雄豪迈又不乏细腻柔媚之处，题材广阔又善化用典故\n",
       "入词，抒写力图恢复国家统一的爱国热情，倾诉壮志难酬的悲愤，对当时执政者的屈辱求和颇多谴责，也有不少吟咏祖国河山的作品。 [4] [68]有《稼轩长短句》等传世。今人辑有《辛稼轩诗文钞存》。\n",
       "辛弃疾的诗，据辛启泰所辑《稼轩集抄存》收诗111首。邓广铭辑校《辛稼轩诗文抄存》清除误收，增补遗漏，得诗124首。其后，孔凡礼的《辛稼轩诗词补辑》又新补诗19首。现存辛诗，共133首。辛诗从各个不同的侧面，反映了作者的生活和思想情感，可与其\n",
       "词相证，其中《送别湖南部曲》，自写政治遭遇，可与《鹧鸪天·壮岁旌旗拥万夫》对读；“有时思到难思处，拍碎栏干人不知”（《鹤鸣亭绝句》），感叹英雄失意，也与《水龙吟·登建康赏心亭》合拍，而“竹杖芒鞋看瀑回，暮年筋力倦崔嵬”《同杜叔高祝彦集观天保\n",
       "庵瀑布主人留饮两日\n",
       "辛弃疾词具有强烈的爱国思想和战斗精神。辛词的爱国思想与战斗精神首先表现在他对被分裂的北方的怀念和对抗金斗争的赞扬上。他词里不但经常出现“西北有神州”“西北是长安”等句子，还强烈表现他不能忍受南北分裂的局面。他在《贺新郎·用前韵送杜叔高》词中\n",
       "说：“起望衣冠神州路，白日销残战骨，叹夷甫诸人清绝。夜半狂歌悲风起，听铮铮阵马檐间铁，南共北，正分裂。”比较突出地表现这种思想。他青年时期曾直接参加北方人民的抗金斗争后来在词里还经常想起这种“马作的卢飞快，弓如霹雳弦惊”（《破阵子·为陈同甫\n",
       "赋壮词以寄之》），“\n",
       "辛弃疾的独特成就是他创造了一种恢宏苍茫和阔大的词境，如《水龙吟·登建康赏心亭》。与辛词雄浑苍茫的意境相对应的是其意象的壮观飞动与充满生命的活力。这方面最成功、最得心应手的是他笔下的高大的抒情主人公形象，如《贺新郎·同父见和再用韵答之》。同时\n",
       "他的婉约词也写得独到精致、典雅妩媚。如《摸鱼儿·更能消几番风雨》。 [12] \n",
       "根据上述已知信息，专业的来回答用户的问题。如果无法从中得到答案，请说 “根据已知信息无法回答该问题” 或 “没有提供足够的相关信息”，不允许在答案中添加编造成分，答案请使用中文。 问题是：辛弃疾诗歌特点</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 向量+全文融合检索，之后再reranker，然后将检索结果与问题进行prompt提交给大模型\n",
    "lindorm = Lindorm(\"test\")\n",
    "def demo_chat_with_child_chunking(query):\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    search_result = lindorm.lindormSearch.rrf_search(query, topk * 2)\n",
    "    texts = [item[\"_source\"][\"text_field\"] for item in search_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    prompt_context = \"\\n\".join(item['chunk'] for item in reranker_result[0:topk])\n",
    "    ali_qwen = AliQwen()\n",
    "    prompt = ali_qwen.gen_prompt(query, prompt_context)\n",
    "    output_text = \"\"\n",
    "    for part in ali_qwen.chat_stream(prompt):\n",
    "        output_text = part \n",
    "        wrapped_text = wrap_text(output_text, 80)\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='color: red;'>{wrapped_text}</pre>\"))\n",
    "    \n",
    "    wrapped_text = wrap_text(prompt, 120)\n",
    "    display(HTML(f\"<pre>提示模版为:\\n{wrapped_text}</pre>\"))\n",
    "    lindorm.close()\n",
    "\n",
    "query=\"辛弃疾诗歌特点\"\n",
    "demo_chat_with_child_chunking(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style='color: red;'>辛弃疾的诗歌特点可以从以下几个方面来概括：\n",
       "1. **</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 向量+全文融合检索，之后再reranker，然后再查找父表中的context字段，与问题进行prompt提交大模型\n",
    "lindorm = Lindorm(\"test\")\n",
    "def demo_chat_with_parent(query):\n",
    "    topk=int(Config.SEARCH_TOP_K)\n",
    "    search_result = lindorm.lindormSearch.rrf_search(query, topk * 2)\n",
    "    texts = [item[\"_source\"][\"text_field\"] for item in search_result]\n",
    "    reranker_result = lindorm.lindormAI.reranker(query, texts)\n",
    "    reranked_origin_result = lindorm.lindormAI.handler_reranker(search_result, reranker_result, topk)\n",
    "    unique_document_ids = list(OrderedDict.fromkeys(item['_source']['document_id'] for item in reranked_origin_result))\n",
    "    contexts = []\n",
    "    for document_id in unique_document_ids:\n",
    "        contexts.append(lindorm.lindormSearch.get_parent_context(document_id=document_id))\n",
    "    prompt_context = \"\\n\".join(contexts)        \n",
    "    ali_qwen = AliQwen()\n",
    "    prompt = ali_qwen.gen_prompt(query, prompt_context)    \n",
    "    # stream\n",
    "    for part in ali_qwen.chat_stream(prompt):\n",
    "        output_text = part \n",
    "        wrapped_text = wrap_text(output_text, 80)\n",
    "        clear_output(wait=True)\n",
    "        display(HTML(f\"<pre style='color: red;'>{wrapped_text}</pre>\"))\n",
    "    \n",
    "    wrapped_text = wrap_text(prompt, 120)\n",
    "    display(HTML(f\"<pre>提示模版为:\\n{wrapped_text}</pre>\")) \n",
    "    lindorm.close()\n",
    "    \n",
    "query=\"辛弃疾诗歌特点\"\n",
    "demo_chat_with_parent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
